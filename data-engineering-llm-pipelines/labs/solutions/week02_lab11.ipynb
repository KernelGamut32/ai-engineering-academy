{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bd3b56",
   "metadata": {},
   "source": [
    "# Lab 11 — Data Quality Dimensions & Thresholded Alerts\n",
    " \n",
    "**Focus Area:** Quality dimensions — **Completeness, Validity, Consistency, Timeliness** with thresholds & alerts\n",
    "\n",
    "> In this lab you'll operationalize data‑quality checks across four core dimensions and wire lightweight **alerts** that block or warn before downstream LLM processing. You'll reuse artifacts from earlier labs and produce a small, reusable **DQ report**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a718d",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Define and compute metrics for **completeness**, **validity**, **consistency**, and **timeliness**.\n",
    "2. Set **thresholds** (warn vs fail) and emit a compact machine‑readable **DQ report**.\n",
    "3. Detect **consistency** issues (e.g., country naming) using a reference dimension.\n",
    "4. Integrate DQ checks with earlier **Pandera** schema validation and **profiling** outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef51e57",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `pandera` (optional), `pyarrow`  \n",
    "- Artifacts (preferred): from previous lab — `users_clean.parquet`, `per_customer.parquet`\n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "\n",
    "### Loading Artifacts (Preferred Method)\n",
    "\n",
    "If you have completed earlier labs, load the existing artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fc8a466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 1471 users from artifacts/clean/users_clean.parquet\n",
      "✓ Loaded 4 customer records from artifacts/clean/per_customer.parquet\n",
      "\n",
      "Users columns: ['user_id', 'email', 'age', 'country', 'signup_date', 'spend', 'is_marketing_opt_in', 'country_norm', 'spend_usd', 'signup_dt']\n",
      "Per-customer columns: ['CustomerID', 'n_orders', 'freight_mean', 'freight_sum', 'CompanyName', 'Country', 'spend_segment']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Load users data from clean artifacts\n",
    "users_path = Path('artifacts/clean/users_clean.parquet')\n",
    "if users_path.exists():\n",
    "    users2 = pd.read_parquet(users_path)\n",
    "    print(f\"✓ Loaded {len(users2)} users from {users_path}\")\n",
    "else:\n",
    "    print(f\"✗ {users_path} not found. Use synthetic data fallback below.\")\n",
    "\n",
    "# Load per-customer aggregated data\n",
    "per_customer_path = Path('artifacts/clean/per_customer.parquet')\n",
    "if per_customer_path.exists():\n",
    "    per_customer = pd.read_parquet(per_customer_path)\n",
    "    print(f\"✓ Loaded {len(per_customer)} customer records from {per_customer_path}\")\n",
    "else:\n",
    "    print(f\"✗ {per_customer_path} not found. Use synthetic data fallback below.\")\n",
    "\n",
    "# Examine the structure\n",
    "print(\"\\nUsers columns:\", users2.columns.tolist() if 'users2' in locals() else 'N/A')\n",
    "print(\"Per-customer columns:\", per_customer.columns.tolist() if 'per_customer' in locals() else 'N/A')\n",
    "\n",
    "# country reference (same idea as 2E)\n",
    "country_dim = pd.DataFrame({\n",
    "    'raw': ['USA','U.S.A.','United States','US','usa','U. S. A.','BR','Brasil','DE','Germany','SG','Singapore','N/A'],\n",
    "    'canonical': ['USA','USA','USA','USA','USA','USA','BR','BR','DE','DE','SG','SG','UNKNOWN']\n",
    "})\n",
    "Path('artifacts/reports').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a94c8",
   "metadata": {},
   "source": [
    "### Synthetic Data Fallback\n",
    "\n",
    "If artifacts are missing, synthesize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "rng = np.random.default_rng(11)\n",
    "N = 5000\n",
    "users2 = pd.DataFrame({\n",
    "    'CustomerID': [f'C{i:05d}' for i in range(N)],\n",
    "    'email': [f'user{i}@example.com' if rng.random()>.01 else None for i in range(N)],\n",
    "    'age': rng.integers(16, 80, size=N).astype('Int64'),\n",
    "    'signup_dt': pd.to_datetime('2025-01-01') + pd.to_timedelta(rng.integers(0, 40, size=N), unit='D'),\n",
    "    'country': rng.choice(['US','usa','United States','DE','SG','BR','N/A'], size=N, p=[.35,.05,.08,.2,.2,.1,.02]),\n",
    "    'ltv_usd': np.round(np.clip(rng.lognormal(3.1, .7, size=N), 0, 1e5), 2),\n",
    "})\n",
    "orders = pd.DataFrame({\n",
    "    'OrderID': np.arange(10_000, 10_000+N*2),\n",
    "    'CustomerID': rng.choice(users2['CustomerID'], size=N*2),\n",
    "    'OrderDate': pd.to_datetime('2025-02-01') + pd.to_timedelta(rng.integers(0, 10, size=N*2), unit='D'),\n",
    "    'Freight': np.round(np.clip(rng.lognormal(3.0, 0.7, size=N*2), 0, 2e4), 2)\n",
    "})\n",
    "\n",
    "# country reference (same idea as 2E)\n",
    "country_dim = pd.DataFrame({\n",
    "    'raw': ['USA','U.S.A.','United States','US','usa','U. S. A.','BR','Brasil','DE','Germany','SG','Singapore','N/A'],\n",
    "    'canonical': ['USA','USA','USA','USA','USA','USA','BR','BR','DE','DE','SG','SG','UNKNOWN']\n",
    "})\n",
    "Path('artifacts/reports').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7ef90",
   "metadata": {},
   "source": [
    "## Part A — Define Quality Dimensions & Base Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb80bc2",
   "metadata": {},
   "source": [
    "**Note:** If using real artifacts, adjust column names as needed. The examples below assume the synthetic dataset structure, but you can adapt them to match your `users_clean.parquet` schema (e.g., `Email` vs `email`, `Age` vs `age`, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f653f",
   "metadata": {},
   "source": [
    "### A1. Completeness (null rate on required columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5007755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'email', 'age', 'country', 'signup_date', 'spend', 'is_marketing_opt_in', 'country_norm', 'spend_usd', 'signup_dt']\n"
     ]
    }
   ],
   "source": [
    "print(users2.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8a083a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 0.0,\n",
       " 'email': 0.0,\n",
       " 'signup_date': 0.04078857919782461,\n",
       " 'spend_usd': 0.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust column names to match your actual dataset\n",
    "# For synthetic data: ['CustomerID','email','signup_dt']\n",
    "# For real artifacts, check: users2.columns.tolist()\n",
    "required_cols = ['user_id','email','signup_date', 'spend_usd']  # Update as needed\n",
    "null_rates = users2[required_cols].isna().mean().to_dict()\n",
    "null_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561708d",
   "metadata": {},
   "source": [
    "### A2. Validity (type/range rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf7e1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age_in_range_rate': 1.0, 'ltv_nonnegative_rate': 1.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_age = users2['age'].between(0, 120) | users2['age'].isna()\n",
    "valid_ltv = users2['spend_usd'].ge(0) | users2['spend_usd'].isna()\n",
    "validity = {\n",
    "    'age_in_range_rate': float(valid_age.mean()),\n",
    "    'ltv_nonnegative_rate': float(valid_ltv.mean())\n",
    "}\n",
    "validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d6709",
   "metadata": {},
   "source": [
    "### A3. Consistency (country naming via reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57a71db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88841882601798"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize, then left join to reference mapping\n",
    "norm = (users2['country'].astype('string')\n",
    "         .str.replace('.','', regex=False)\n",
    "         .str.replace(' ','', regex=False)\n",
    "         .str.upper())\n",
    "ref = country_dim.assign(raw_key = country_dim['raw'].str.replace('.','', regex=False).str.replace(' ','', regex=False).str.upper())\n",
    "map_df = pd.DataFrame({'country_key': norm})\n",
    "map_df = map_df.merge(ref[['raw_key','canonical']], left_on='country_key', right_on='raw_key', how='left')\n",
    "consistency_rate = float(map_df['canonical'].notna().mean())\n",
    "consistency_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e8a51",
   "metadata": {},
   "source": [
    "### A4. Timeliness (freshness lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b127ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fresh_rate': 0.2760027192386132, 'lag_p50': 40, 'lag_p95': 41}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "now = pd.Timestamp('2025-02-15')  # fixed for reproducibility; replace with pd.Timestamp.utcnow()\n",
    "\n",
    "# Convert signup_date to datetime if it's stored as string\n",
    "users2['signup_date'] = pd.to_datetime(users2['signup_date'], format='mixed')\n",
    "\n",
    "lag_days = (now - users2['signup_date']).dt.days\n",
    "fresh_rate = float((lag_days <= 30).mean())  # % rows updated/arrived within SLA window\n",
    "fresh_stats = {'lag_p50': int(lag_days.median()), 'lag_p95': int(lag_days.quantile(0.95))}\n",
    "{'fresh_rate': fresh_rate, **fresh_stats}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7fb7",
   "metadata": {},
   "source": [
    "**Checkpoint:** In your words, distinguish validity vs consistency for `country`.\n",
    "\n",
    "*Answer:* Validity checks whether the country field contains a value within an expected set of valid values (e.g., not null, not an empty string). Consistency checks whether the country naming follows standardized conventions by mapping various representations (e.g., 'US', 'usa', 'United States') to a single canonical form (e.g., 'USA'), ensuring uniform representation across the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886229e5",
   "metadata": {},
   "source": [
    "## Part B — Thresholds: Warn vs Fail & Compact Alert Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864aad9",
   "metadata": {},
   "source": [
    "### B1. Define thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb7dd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'completeness': { 'email_null_rate_max': 0.02, 'signup_dt_null_rate_max': 0.00 },\n",
    "    'validity':     { 'age_in_range_min': 0.995,  'ltv_nonnegative_min': 1.00 },\n",
    "    'consistency':  { 'country_mapped_min': 0.98 },\n",
    "    'timeliness':   { 'fresh_rate_min': 0.90, 'lag_p95_max': 40 }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216fea8",
   "metadata": {},
   "source": [
    "### B2. Evaluate metrics against thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82be2124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'level': 'WARN',\n",
       "  'dimension': 'consistency',\n",
       "  'metric': 'country_mapped_rate',\n",
       "  'value': 0.88841882601798,\n",
       "  'target': 0.98,\n",
       "  'message': 'New/unmapped country variants observed'},\n",
       " {'level': 'WARN',\n",
       "  'dimension': 'timeliness',\n",
       "  'metric': 'fresh_rate',\n",
       "  'value': 0.2760027192386132,\n",
       "  'target': 0.9,\n",
       "  'message': 'Records stale beyond SLA'},\n",
       " {'level': 'WARN',\n",
       "  'dimension': 'timeliness',\n",
       "  'metric': 'lag_p95',\n",
       "  'value': 41.0,\n",
       "  'target': 40.0,\n",
       "  'message': 'Tail latency too high'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_dq(null_rates, validity, consistency_rate, fresh_rate, fresh_stats, thresholds):\n",
    "    alerts = []\n",
    "    def add(level, dim, metric, value, target, msg):\n",
    "        alerts.append({'level': level, 'dimension': dim, 'metric': metric, 'value': float(value), 'target': float(target), 'message': msg})\n",
    "\n",
    "    # Completeness\n",
    "    if null_rates['email'] > thresholds['completeness']['email_null_rate_max']:\n",
    "        add('FAIL','completeness','email_null_rate', null_rates['email'], thresholds['completeness']['email_null_rate_max'], 'Email null rate too high')\n",
    "    elif null_rates['email'] > thresholds['completeness']['email_null_rate_max'] * 0.8:\n",
    "        add('WARN','completeness','email_null_rate', null_rates['email'], thresholds['completeness']['email_null_rate_max'], 'Email null rate nearing limit')\n",
    "\n",
    "    # Validity\n",
    "    if validity['age_in_range_rate'] < thresholds['validity']['age_in_range_min']:\n",
    "        add('FAIL','validity','age_in_range_rate', validity['age_in_range_rate'], thresholds['validity']['age_in_range_min'], 'Age out of range')\n",
    "    if validity['ltv_nonnegative_rate'] < thresholds['validity']['ltv_nonnegative_min']:\n",
    "        add('FAIL','validity','ltv_nonnegative_rate', validity['ltv_nonnegative_rate'], thresholds['validity']['ltv_nonnegative_min'], 'Negative LTV detected')\n",
    "\n",
    "    # Consistency\n",
    "    if consistency_rate < thresholds['consistency']['country_mapped_min']:\n",
    "        add('WARN','consistency','country_mapped_rate', consistency_rate, thresholds['consistency']['country_mapped_min'], 'New/unmapped country variants observed')\n",
    "\n",
    "    # Timeliness\n",
    "    if fresh_rate < thresholds['timeliness']['fresh_rate_min']:\n",
    "        add('WARN','timeliness','fresh_rate', fresh_rate, thresholds['timeliness']['fresh_rate_min'], 'Records stale beyond SLA')\n",
    "    if fresh_stats['lag_p95'] > thresholds['timeliness']['lag_p95_max']:\n",
    "        add('WARN','timeliness','lag_p95', fresh_stats['lag_p95'], thresholds['timeliness']['lag_p95_max'], 'Tail latency too high')\n",
    "\n",
    "    return alerts\n",
    "\n",
    "alerts = evaluate_dq(null_rates, validity, consistency_rate, fresh_rate, fresh_stats, thresholds)\n",
    "alerts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bff2e6",
   "metadata": {},
   "source": [
    "### B3. Persist a machine‑readable DQ report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "602681ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wrote artifacts/reports/dq_report.json'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "Path('artifacts/reports').mkdir(parents=True, exist_ok=True)\n",
    "report = {\n",
    "    'timestamp': pd.Timestamp.utcnow().isoformat(),\n",
    "    'metrics': {\n",
    "        'completeness': null_rates,\n",
    "        'validity': validity,\n",
    "        'consistency': {'country_mapped_rate': consistency_rate},\n",
    "        'timeliness': {'fresh_rate': fresh_rate, **fresh_stats}\n",
    "    },\n",
    "    'thresholds': thresholds,\n",
    "    'alerts': alerts\n",
    "}\n",
    "with open('artifacts/reports/dq_report.json','w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "'Wrote artifacts/reports/dq_report.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80244ff4",
   "metadata": {},
   "source": [
    "**Checkpoint:** Which alerts would be **FAIL** (block) vs **WARN** (notify) in your org? Justify.\n",
    "\n",
    "*Answer:* In most organizations:\n",
    "- **FAIL (block)**: Completeness issues (missing critical identifiers like CustomerID, email, signup_dt), validity issues (negative LTV, age out of valid range) should block the pipeline because they can cause downstream processing errors or incorrect business logic.\n",
    "- **WARN (notify)**: Consistency issues (country naming variants) and timeliness issues (stale data) should trigger warnings because they don't prevent processing but indicate data quality degradation that needs attention. These can be tolerated temporarily while being monitored and addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4140de",
   "metadata": {},
   "source": [
    "## Part C — Hook into Validation & Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e813ecf0",
   "metadata": {},
   "source": [
    "### C1. Combine with Pandera (optional gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdb05347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera.pandas as pa\n",
    "from pandera import Column, Check\n",
    "UsersSchema = pa.DataFrameSchema({\n",
    "    'user_id': Column(pa.Int64, nullable=False),\n",
    "    'email': Column(object, nullable=False, checks=Check.str_matches(r'^.+@.+\\..+$')),\n",
    "    'age': Column(pa.Float64, nullable=False, checks=Check.in_range(0,120)),\n",
    "    'signup_date': Column(pa.DateTime, nullable=False),\n",
    "    'spend_usd': Column(pa.Float64, nullable=False, checks=Check.ge(0))\n",
    "})\n",
    "try:\n",
    "    _ = UsersSchema.validate(users2.dropna(subset=['user_id','email','signup_date']), lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print('Schema gate failed; see failure cases below:')\n",
    "    display(err.failure_cases.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2397d6c5",
   "metadata": {},
   "source": [
    "### C2. Single boolean to drive CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad31dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'level': 'WARN', 'dimension': 'consistency', 'metric': 'country_mapped_rate', 'value': 0.88841882601798, 'target': 0.98, 'message': 'New/unmapped country variants observed'}, {'level': 'WARN', 'dimension': 'timeliness', 'metric': 'fresh_rate', 'value': 0.2760027192386132, 'target': 0.9, 'message': 'Records stale beyond SLA'}, {'level': 'WARN', 'dimension': 'timeliness', 'metric': 'lag_p95', 'value': 41.0, 'target': 40.0, 'message': 'Tail latency too high'}]\n",
      "DQ status => WARN\n"
     ]
    }
   ],
   "source": [
    "#print(alerts)\n",
    "fail = any(a['level']=='FAIL' for a in alerts)\n",
    "warn = any(a['level']=='WARN' for a in alerts)\n",
    "print('DQ status =>', 'FAIL' if fail else 'WARN' if warn else 'OK')\n",
    "# In CI: sys.exit(1) if fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836af25",
   "metadata": {},
   "source": [
    "## Part D — Wrap‑Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db77391",
   "metadata": {},
   "source": [
    "### Reflection Questions\n",
    "\n",
    "1. **Give one concrete metric per dimension that you computed and the threshold you chose.**\n",
    "   - **Completeness**: Email null rate with threshold of 2% maximum\n",
    "   - **Validity**: Age in range (0-120) with threshold of 99.5% minimum\n",
    "   - **Consistency**: Country mapped rate with threshold of 98% minimum\n",
    "   - **Timeliness**: Fresh rate (within 30 days) with threshold of 90% minimum\n",
    "\n",
    "2. **Which alerts would block the pipeline vs notify only? Why?**\n",
    "   - **Block (FAIL)**: Missing signup dates, negative LTV values, excessive null emails, out-of-range ages - these indicate fundamental data integrity issues that would cause downstream processing errors\n",
    "   - **Notify (WARN)**: Country naming inconsistencies, stale data, high tail latency - these are quality issues that should be monitored and addressed but don't prevent processing\n",
    "\n",
    "3. **Where in your pipeline would you store and review the DQ report?**\n",
    "   - Store in a time-series database or object storage with timestamps for historical tracking\n",
    "   - Review in automated dashboards (e.g., Grafana, Tableau) with alerting capabilities\n",
    "   - Integrate into CI/CD pipeline logs and monitoring systems\n",
    "   - Archive reports in data lake for audit trails and trend analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f02c4",
   "metadata": {},
   "source": [
    "### Export DQ alerts to CSV (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0035e669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 3 alerts to artifacts/reports/dq_alerts.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dimension",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "message",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "e119069c-77f9-4c2a-a875-e7b3425abedb",
       "rows": [
        [
         "0",
         "WARN",
         "consistency",
         "country_mapped_rate",
         "0.88841882601798",
         "0.98",
         "New/unmapped country variants observed"
        ],
        [
         "1",
         "WARN",
         "timeliness",
         "fresh_rate",
         "0.2760027192386132",
         "0.9",
         "Records stale beyond SLA"
        ],
        [
         "2",
         "WARN",
         "timeliness",
         "lag_p95",
         "41.0",
         "40.0",
         "Tail latency too high"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>dimension</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WARN</td>\n",
       "      <td>consistency</td>\n",
       "      <td>country_mapped_rate</td>\n",
       "      <td>0.888419</td>\n",
       "      <td>0.98</td>\n",
       "      <td>New/unmapped country variants observed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WARN</td>\n",
       "      <td>timeliness</td>\n",
       "      <td>fresh_rate</td>\n",
       "      <td>0.276003</td>\n",
       "      <td>0.90</td>\n",
       "      <td>Records stale beyond SLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WARN</td>\n",
       "      <td>timeliness</td>\n",
       "      <td>lag_p95</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>40.00</td>\n",
       "      <td>Tail latency too high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level    dimension               metric      value  target  \\\n",
       "0  WARN  consistency  country_mapped_rate   0.888419    0.98   \n",
       "1  WARN   timeliness           fresh_rate   0.276003    0.90   \n",
       "2  WARN   timeliness              lag_p95  41.000000   40.00   \n",
       "\n",
       "                                  message  \n",
       "0  New/unmapped country variants observed  \n",
       "1                Records stale beyond SLA  \n",
       "2                   Tail latency too high  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Export alerts to CSV for review\n",
    "if alerts:\n",
    "    alerts_df = pd.DataFrame(alerts)\n",
    "    alerts_df.to_csv('artifacts/reports/dq_alerts.csv', index=False)\n",
    "    print(f'Exported {len(alerts)} alerts to artifacts/reports/dq_alerts.csv')\n",
    "    display(alerts_df)\n",
    "else:\n",
    "    print('No alerts to export - data quality checks passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77205f81",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "- **Too strict thresholds** causing constant red; start lenient and tighten over time\n",
    "- **Ambiguous units** (days vs hours) for timeliness - always document clearly\n",
    "- **Mixing validity (range) with consistency (naming)** - keep dimensions distinct\n",
    "- **Not storing historical DQ reports** - trends are as important as point-in-time checks\n",
    "- **Ignoring warn alerts** - they accumulate and eventually become failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b33b53",
   "metadata": {},
   "source": [
    "## Solution Snippets (reference)\n",
    "\n",
    "**Null‑rate dict for any set of columns:**\n",
    "```python\n",
    "lambda df, cols: df[cols].isna().mean().to_dict()\n",
    "```\n",
    "\n",
    "**Country mapping coverage:**\n",
    "```python\n",
    "coverage = (map_df['canonical'].notna().mean())\n",
    "```\n",
    "\n",
    "**SLA freshness check for arbitrary datetime col:**\n",
    "```python\n",
    "lambda s, now, days: float(((now - s).dt.days <= days).mean())\n",
    "```\n",
    "\n",
    "**CI fail/warn toggle:**\n",
    "```python\n",
    "fail = any(a['level']=='FAIL' for a in alerts)\n",
    "warn = any(a['level']=='WARN' for a in alerts)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
