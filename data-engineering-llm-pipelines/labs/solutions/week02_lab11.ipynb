{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35bd3b56",
   "metadata": {},
   "source": [
    "# Lab 11 — Data Quality Dimensions & Thresholded Alerts\n",
    " \n",
    "**Focus Area:** Quality dimensions — **Completeness, Validity, Consistency, Timeliness** with thresholds & alerts\n",
    "\n",
    "> In this lab you'll operationalize data‑quality checks across four core dimensions and wire lightweight **alerts** that block or warn before downstream LLM processing. You'll reuse artifacts from earlier labs and produce a small, reusable **DQ report**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9a718d",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Define and compute metrics for **completeness**, **validity**, **consistency**, and **timeliness**.\n",
    "2. Set **thresholds** (warn vs fail) and emit a compact machine‑readable **DQ report**.\n",
    "3. Detect **consistency** issues (e.g., country naming) using a reference dimension.\n",
    "4. Integrate DQ checks with earlier **Pandera** schema validation and **profiling** outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef51e57",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `pandera` (optional), `pyarrow`  \n",
    "- Artifacts (preferred): from previous lab — `users2_clean.parquet`, `per_customer_enriched.parquet`\n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "\n",
    "If artifacts are missing, synthesize data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "rng = np.random.default_rng(11)\n",
    "N = 5000\n",
    "users2 = pd.DataFrame({\n",
    "    'CustomerID': [f'C{i:05d}' for i in range(N)],\n",
    "    'email': [f'user{i}@example.com' if rng.random()>.01 else None for i in range(N)],\n",
    "    'age': rng.integers(16, 80, size=N).astype('Int64'),\n",
    "    'signup_dt': pd.to_datetime('2025-01-01') + pd.to_timedelta(rng.integers(0, 40, size=N), unit='D'),\n",
    "    'country': rng.choice(['US','usa','United States','DE','SG','BR','N/A'], size=N, p=[.35,.05,.08,.2,.2,.1,.02]),\n",
    "    'ltv_usd': np.round(np.clip(rng.lognormal(3.1, .7, size=N), 0, 1e5), 2),\n",
    "})\n",
    "orders = pd.DataFrame({\n",
    "    'OrderID': np.arange(10_000, 10_000+N*2),\n",
    "    'CustomerID': rng.choice(users2['CustomerID'], size=N*2),\n",
    "    'OrderDate': pd.to_datetime('2025-02-01') + pd.to_timedelta(rng.integers(0, 10, size=N*2), unit='D'),\n",
    "    'Freight': np.round(np.clip(rng.lognormal(3.0, 0.7, size=N*2), 0, 2e4), 2)\n",
    "})\n",
    "\n",
    "# country reference (same idea as 2E)\n",
    "country_dim = pd.DataFrame({\n",
    "    'raw': ['USA','U.S.A.','United States','US','usa','U. S. A.','BR','Brasil','DE','Germany','SG','Singapore','N/A'],\n",
    "    'canonical': ['USA','USA','USA','USA','USA','USA','BR','BR','DE','DE','SG','SG','UNKNOWN']\n",
    "})\n",
    "Path('artifacts/reports').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc7ef90",
   "metadata": {},
   "source": [
    "## Part A — Define Quality Dimensions & Base Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f653f",
   "metadata": {},
   "source": [
    "### A1. Completeness (null rate on required columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_cols = ['CustomerID','email','signup_dt']\n",
    "null_rates = users2[required_cols].isna().mean().to_dict()\n",
    "null_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561708d",
   "metadata": {},
   "source": [
    "### A2. Validity (type/range rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_age = users2['age'].between(0, 120) | users2['age'].isna()\n",
    "valid_ltv = users2['ltv_usd'].ge(0) | users2['ltv_usd'].isna()\n",
    "validity = {\n",
    "    'age_in_range_rate': float(valid_age.mean()),\n",
    "    'ltv_nonnegative_rate': float(valid_ltv.mean())\n",
    "}\n",
    "validity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d6709",
   "metadata": {},
   "source": [
    "### A3. Consistency (country naming via reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57a71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize, then left join to reference mapping\n",
    "norm = (users2['country'].astype('string')\n",
    "         .str.replace('.','', regex=False)\n",
    "         .str.replace(' ','', regex=False)\n",
    "         .str.upper())\n",
    "ref = country_dim.assign(raw_key = country_dim['raw'].str.replace('.','', regex=False).str.replace(' ','', regex=False).str.upper())\n",
    "map_df = pd.DataFrame({'country_key': norm})\n",
    "map_df = map_df.merge(ref[['raw_key','canonical']], left_on='country_key', right_on='raw_key', how='left')\n",
    "consistency_rate = float(map_df['canonical'].notna().mean())\n",
    "consistency_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e8a51",
   "metadata": {},
   "source": [
    "### A4. Timeliness (freshness lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b127ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "now = pd.Timestamp('2025-02-15')  # fixed for reproducibility; replace with pd.Timestamp.utcnow()\n",
    "lag_days = (now - users2['signup_dt']).dt.days\n",
    "fresh_rate = float((lag_days <= 30).mean())  # % rows updated/arrived within SLA window\n",
    "fresh_stats = {'lag_p50': int(lag_days.median()), 'lag_p95': int(lag_days.quantile(0.95))}\n",
    "{'fresh_rate': fresh_rate, **fresh_stats}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f7fb7",
   "metadata": {},
   "source": [
    "**Checkpoint:** In your words, distinguish validity vs consistency for `country`.\n",
    "\n",
    "*Answer:* Validity checks whether the country field contains a value within an expected set of valid values (e.g., not null, not an empty string). Consistency checks whether the country naming follows standardized conventions by mapping various representations (e.g., 'US', 'usa', 'United States') to a single canonical form (e.g., 'USA'), ensuring uniform representation across the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886229e5",
   "metadata": {},
   "source": [
    "## Part B — Thresholds: Warn vs Fail & Compact Alert Object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b864aad9",
   "metadata": {},
   "source": [
    "### B1. Define thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7dd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {\n",
    "    'completeness': { 'email_null_rate_max': 0.02, 'signup_dt_null_rate_max': 0.00 },\n",
    "    'validity':     { 'age_in_range_min': 0.995,  'ltv_nonnegative_min': 1.00 },\n",
    "    'consistency':  { 'country_mapped_min': 0.98 },\n",
    "    'timeliness':   { 'fresh_rate_min': 0.90, 'lag_p95_max': 40 }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216fea8",
   "metadata": {},
   "source": [
    "### B2. Evaluate metrics against thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be2124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dq(null_rates, validity, consistency_rate, fresh_rate, fresh_stats, thresholds):\n",
    "    alerts = []\n",
    "    def add(level, dim, metric, value, target, msg):\n",
    "        alerts.append({'level': level, 'dimension': dim, 'metric': metric, 'value': float(value), 'target': float(target), 'message': msg})\n",
    "\n",
    "    # Completeness\n",
    "    if null_rates['email'] > thresholds['completeness']['email_null_rate_max']:\n",
    "        add('FAIL','completeness','email_null_rate', null_rates['email'], thresholds['completeness']['email_null_rate_max'], 'Email null rate too high')\n",
    "    elif null_rates['email'] > thresholds['completeness']['email_null_rate_max'] * 0.8:\n",
    "        add('WARN','completeness','email_null_rate', null_rates['email'], thresholds['completeness']['email_null_rate_max'], 'Email null rate nearing limit')\n",
    "\n",
    "    if null_rates['signup_dt'] > thresholds['completeness']['signup_dt_null_rate_max']:\n",
    "        add('FAIL','completeness','signup_dt_null_rate', null_rates['signup_dt'], thresholds['completeness']['signup_dt_null_rate_max'], 'Missing signup_dt not allowed')\n",
    "\n",
    "    # Validity\n",
    "    if validity['age_in_range_rate'] < thresholds['validity']['age_in_range_min']:\n",
    "        add('FAIL','validity','age_in_range_rate', validity['age_in_range_rate'], thresholds['validity']['age_in_range_min'], 'Age out of range')\n",
    "    if validity['ltv_nonnegative_rate'] < thresholds['validity']['ltv_nonnegative_min']:\n",
    "        add('FAIL','validity','ltv_nonnegative_rate', validity['ltv_nonnegative_rate'], thresholds['validity']['ltv_nonnegative_min'], 'Negative LTV detected')\n",
    "\n",
    "    # Consistency\n",
    "    if consistency_rate < thresholds['consistency']['country_mapped_min']:\n",
    "        add('WARN','consistency','country_mapped_rate', consistency_rate, thresholds['consistency']['country_mapped_min'], 'New/unmapped country variants observed')\n",
    "\n",
    "    # Timeliness\n",
    "    if fresh_rate < thresholds['timeliness']['fresh_rate_min']:\n",
    "        add('WARN','timeliness','fresh_rate', fresh_rate, thresholds['timeliness']['fresh_rate_min'], 'Records stale beyond SLA')\n",
    "    if fresh_stats['lag_p95'] > thresholds['timeliness']['lag_p95_max']:\n",
    "        add('WARN','timeliness','lag_p95', fresh_stats['lag_p95'], thresholds['timeliness']['lag_p95_max'], 'Tail latency too high')\n",
    "\n",
    "    return alerts\n",
    "\n",
    "alerts = evaluate_dq(null_rates, validity, consistency_rate, fresh_rate, fresh_stats, thresholds)\n",
    "alerts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bff2e6",
   "metadata": {},
   "source": [
    "### B3. Persist a machine‑readable DQ report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602681ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "Path('artifacts/reports').mkdir(parents=True, exist_ok=True)\n",
    "report = {\n",
    "    'timestamp': pd.Timestamp.utcnow().isoformat(),\n",
    "    'metrics': {\n",
    "        'completeness': null_rates,\n",
    "        'validity': validity,\n",
    "        'consistency': {'country_mapped_rate': consistency_rate},\n",
    "        'timeliness': {'fresh_rate': fresh_rate, **fresh_stats}\n",
    "    },\n",
    "    'thresholds': thresholds,\n",
    "    'alerts': alerts\n",
    "}\n",
    "with open('artifacts/reports/dq_report.json','w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "'Wrote artifacts/reports/dq_report.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80244ff4",
   "metadata": {},
   "source": [
    "**Checkpoint:** Which alerts would be **FAIL** (block) vs **WARN** (notify) in your org? Justify.\n",
    "\n",
    "*Answer:* In most organizations:\n",
    "- **FAIL (block)**: Completeness issues (missing critical identifiers like CustomerID, email, signup_dt), validity issues (negative LTV, age out of valid range) should block the pipeline because they can cause downstream processing errors or incorrect business logic.\n",
    "- **WARN (notify)**: Consistency issues (country naming variants) and timeliness issues (stale data) should trigger warnings because they don't prevent processing but indicate data quality degradation that needs attention. These can be tolerated temporarily while being monitored and addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4140de",
   "metadata": {},
   "source": [
    "## Part C — Hook into Validation & Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e813ecf0",
   "metadata": {},
   "source": [
    "### C1. Combine with Pandera (optional gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb05347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "from pandera import Column, Check\n",
    "UsersSchema = pa.DataFrameSchema({\n",
    "    'CustomerID': Column(object, nullable=False),\n",
    "    'email': Column(object, nullable=False, checks=Check.str_matches(r'^.+@.+\\..+$')),\n",
    "    'age': Column(pa.Int64, nullable=False, checks=Check.in_range(0,120)),\n",
    "    'signup_dt': Column(object, nullable=False),\n",
    "    'ltv_usd': Column(float, nullable=False, checks=Check.ge(0))\n",
    "})\n",
    "try:\n",
    "    _ = UsersSchema.validate(users2.dropna(subset=['CustomerID','email','signup_dt']), lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    print('Schema gate failed; see failure cases below:')\n",
    "    display(err.failure_cases.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a0f8df",
   "metadata": {},
   "source": [
    "### C2. Lift a few metrics from ydata‑profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose you have profile_full.to_dict() as `prof_dict`\n",
    "# null_rates_profile = {k: v.get('p_missing', None) for k,v in prof_dict['variables'].items()}\n",
    "# Use these to compare vs your completeness thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2397d6c5",
   "metadata": {},
   "source": [
    "### C3. Single boolean to drive CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail = any(a['level']=='FAIL' for a in alerts)\n",
    "warn = any(a['level']=='WARN' for a in alerts)\n",
    "print('DQ status =>', 'FAIL' if fail else 'WARN' if warn else 'OK')\n",
    "# In CI: sys.exit(1) if fail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c836af25",
   "metadata": {},
   "source": [
    "## Part D — Wrap‑Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db77391",
   "metadata": {},
   "source": [
    "### Reflection Questions\n",
    "\n",
    "1. **Give one concrete metric per dimension that you computed and the threshold you chose.**\n",
    "   - **Completeness**: Email null rate with threshold of 2% maximum\n",
    "   - **Validity**: Age in range (0-120) with threshold of 99.5% minimum\n",
    "   - **Consistency**: Country mapped rate with threshold of 98% minimum\n",
    "   - **Timeliness**: Fresh rate (within 30 days) with threshold of 90% minimum\n",
    "\n",
    "2. **Which alerts would block the pipeline vs notify only? Why?**\n",
    "   - **Block (FAIL)**: Missing signup dates, negative LTV values, excessive null emails, out-of-range ages - these indicate fundamental data integrity issues that would cause downstream processing errors\n",
    "   - **Notify (WARN)**: Country naming inconsistencies, stale data, high tail latency - these are quality issues that should be monitored and addressed but don't prevent processing\n",
    "\n",
    "3. **Where in your pipeline would you store and review the DQ report?**\n",
    "   - Store in a time-series database or object storage with timestamps for historical tracking\n",
    "   - Review in automated dashboards (e.g., Grafana, Tableau) with alerting capabilities\n",
    "   - Integrate into CI/CD pipeline logs and monitoring systems\n",
    "   - Archive reports in data lake for audit trails and trend analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f02c4",
   "metadata": {},
   "source": [
    "### Export DQ alerts to CSV (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0035e669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export alerts to CSV for review\n",
    "if alerts:\n",
    "    alerts_df = pd.DataFrame(alerts)\n",
    "    alerts_df.to_csv('artifacts/reports/dq_alerts.csv', index=False)\n",
    "    print(f'Exported {len(alerts)} alerts to artifacts/reports/dq_alerts.csv')\n",
    "    display(alerts_df)\n",
    "else:\n",
    "    print('No alerts to export - data quality checks passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77205f81",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "- **Too strict thresholds** causing constant red; start lenient and tighten over time\n",
    "- **Ambiguous units** (days vs hours) for timeliness - always document clearly\n",
    "- **Mixing validity (range) with consistency (naming)** - keep dimensions distinct\n",
    "- **Not storing historical DQ reports** - trends are as important as point-in-time checks\n",
    "- **Ignoring warn alerts** - they accumulate and eventually become failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b33b53",
   "metadata": {},
   "source": [
    "## Solution Snippets (reference)\n",
    "\n",
    "**Null‑rate dict for any set of columns:**\n",
    "```python\n",
    "lambda df, cols: df[cols].isna().mean().to_dict()\n",
    "```\n",
    "\n",
    "**Country mapping coverage:**\n",
    "```python\n",
    "coverage = (map_df['canonical'].notna().mean())\n",
    "```\n",
    "\n",
    "**SLA freshness check for arbitrary datetime col:**\n",
    "```python\n",
    "lambda s, now, days: float(((now - s).dt.days <= days).mean())\n",
    "```\n",
    "\n",
    "**CI fail/warn toggle:**\n",
    "```python\n",
    "fail = any(a['level']=='FAIL' for a in alerts)\n",
    "warn = any(a['level']=='WARN' for a in alerts)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
