{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f48d6a0",
   "metadata": {},
   "source": [
    "# Week 01, Lab 01 — NumPy & Jupyter EDA Warm‑Up\n",
    "\n",
    "**Your Name**  \n",
    "**Date:** October 26, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Create and reshape NumPy arrays; explain when and why to use `reshape` vs. `ravel`/`flatten`.\n",
    "2. Demonstrate vectorization and broadcasting to replace Python `for` loops.\n",
    "3. Compare **runtime** and **memory footprint** of lists vs. NumPy arrays.\n",
    "4. Use key Jupyter magics for EDA & reproducibility: `%matplotlib inline`, `%timeit`, `%%time`, `%env`, `%%capture`, and `autoreload`.\n",
    "5. Produce a short, reproducible EDA narrative that includes figures, random seeds, and environment/version stamps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b9e809",
   "metadata": {},
   "source": [
    "## Notebook Prologue — Environment & Reproducibility Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas fastparquet matplotlib numpy\n",
    "\n",
    "# Reproducibility & environment snapshot\n",
    "import os, sys, platform, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print({\n",
    "    'python': sys.version.split()[0],\n",
    "    'platform': platform.platform(),\n",
    "    'numpy': np.__version__,\n",
    "    'pandas': pd.__version__,\n",
    "    'matplotlib': matplotlib.__version__,\n",
    "    'pid': os.getpid(),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a281f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A — NumPy Quick Refresh\n",
    "\n",
    "### A1. Arrays vs. Python lists (time & memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7370e47",
   "metadata": {},
   "source": [
    "**Step 1: Create comparable data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfbe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, numpy as np\n",
    "N = 1_000_000\n",
    "py_list = list(range(N))\n",
    "np_array = np.arange(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f008cb2f",
   "metadata": {},
   "source": [
    "**Step 2: Memory footprint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfbb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List memory: container + objects (rough estimate)\n",
    "list_container_bytes = sys.getsizeof(py_list)\n",
    "int_object_bytes = sys.getsizeof(0)  # per small int (implementation dependent)\n",
    "approx_list_bytes = list_container_bytes + N * int_object_bytes\n",
    "\n",
    "# NumPy memory: contiguous buffer\n",
    "numpy_bytes = np_array.nbytes\n",
    "\n",
    "print({'approx_list_bytes': approx_list_bytes, 'numpy_bytes': numpy_bytes})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1fb292",
   "metadata": {},
   "source": [
    "**Step 3: Runtime with `%timeit`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dd3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum(py_list)\n",
    "%timeit np_array.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c514ad",
   "metadata": {},
   "source": [
    "**Checkpoint A1:** NumPy is faster and more memory-efficient because it stores data in contiguous memory blocks and uses vectorized C loops, avoiding Python object overhead. This results in better CPU cache locality and fewer allocations compared to Python lists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e0ace",
   "metadata": {},
   "source": [
    "### A2. Shape, reshape, ravel, and flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4e759",
   "metadata": {},
   "source": [
    "**Step 1: Create and reshape arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(12)\n",
    "x2 = x.reshape(3, 4)\n",
    "x3 = x.reshape(2, 2, 3)\n",
    "x_ravel = x2.ravel()      # view if possible\n",
    "x_flat = x2.flatten()     # always copy\n",
    "print(x2.shape, x3.shape, x_ravel.base is x, x_flat.base is x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d96a84",
   "metadata": {},
   "source": [
    "**Step 2: Prove views vs copies by mutation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutate an element in x2 and observe x, x_ravel, and x_flat\n",
    "x2[0, 0] = 999\n",
    "print(f\"x[0] = {x[0]}\")\n",
    "print(f\"x_ravel[0] = {x_ravel[0]}\")\n",
    "print(f\"x_flat[0] = {x_flat[0]}\")\n",
    "print(f\"\\nx2[0,0] changed to 999\")\n",
    "print(f\"x and x_ravel reflect the change (views)\")\n",
    "print(f\"x_flat does NOT reflect the change (copy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64de0875",
   "metadata": {},
   "source": [
    "**Checkpoint A2:** Prefer `reshape` and `ravel` for performance when you don't need an independent copy, as they return views when possible. Use `flatten` only when you explicitly need a copy to avoid unintended mutations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee5505",
   "metadata": {},
   "source": [
    "### A3. Broadcasting & vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb394c",
   "metadata": {},
   "source": [
    "**Step 1: Broadcasting scalar + vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.arange(5)\n",
    "v_plus = v + 10\n",
    "v_scaled = v * 2\n",
    "print(f\"v = {v}\")\n",
    "print(f\"v + 10 = {v_plus}\")\n",
    "print(f\"v * 2 = {v_scaled}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a4fa8",
   "metadata": {},
   "source": [
    "**Step 2: Broadcasting 2D + 1D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d8b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.arange(12).reshape(3,4)\n",
    "col = np.array([1, 2, 3]).reshape(3,1)\n",
    "M2 = M + col  # adds [1,2,3] to each row\n",
    "print(\"M:\")\n",
    "print(M)\n",
    "print(\"\\ncol:\")\n",
    "print(col)\n",
    "print(\"\\nM + col:\")\n",
    "print(M2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db180cb",
   "metadata": {},
   "source": [
    "**Step 3: Loop vs vectorized timing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3cd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "big = np.random.rand(2_000_000)\n",
    "\n",
    "def py_loop_square(arr):\n",
    "    out = [0.0]*len(arr)\n",
    "    for i, val in enumerate(arr):\n",
    "        out[i] = val*val\n",
    "    return out\n",
    "\n",
    "print(\"Python loop:\")\n",
    "%timeit py_loop_square(big)\n",
    "\n",
    "print(\"\\nNumPy vectorized:\")\n",
    "%timeit big*big"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9261b16",
   "metadata": {},
   "source": [
    "**Checkpoint A3:** The vectorized NumPy operation is typically 10-100× faster than the Python loop, depending on hardware. This demonstrates the power of vectorization for numerical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235a255a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part B — Jupyter for EDA & Pipelines\n",
    "\n",
    "### B1. Jupyter magics you'll actually use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e00128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Inline plotting for reports/notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12811ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2) Timing\n",
    "import time\n",
    "_ = [time.sleep(0.001) for _ in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6615c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Micro-benchmarks (repeat/average)\n",
    "import numpy as np\n",
    "arr = np.random.rand(1_000_00)\n",
    "%timeit arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b9f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Environment variables for pipelines\n",
    "%env DATA_DIR=./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7880650",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "# 5) Capture noisy cell output (useful when logging)\n",
    "print('This will be captured, not printed.')\n",
    "\n",
    "# Verify capture worked\n",
    "print(\"If you see this, capture is working (the above print was captured)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Autoreload during iterative development\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d983093",
   "metadata": {},
   "source": [
    "> **Note:** `%%time` measures a single run (wall & CPU time). `%timeit` runs multiple times and reports a stable average — better for micro‑benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d12ab",
   "metadata": {},
   "source": [
    "### B2. Mini‑EDA narrative with reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71b07a2",
   "metadata": {},
   "source": [
    "**Step 1: Create a small synthetic dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3070a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "rng = np.random.default_rng(SEED)\n",
    "n = 500\n",
    "df = pd.DataFrame({\n",
    "    'user_id': np.arange(n),\n",
    "    'age': rng.integers(18, 70, size=n),\n",
    "    'country': rng.choice(['US', 'SG', 'DE', 'BR', 'IN'], size=n, p=[0.35,0.15,0.2,0.15,0.15]),\n",
    "    'sessions': rng.poisson(3, size=n),\n",
    "    'avg_session_sec': rng.normal(300, 50, size=n).clip(30, 1200)\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c334b78",
   "metadata": {},
   "source": [
    "**Step 2: Quick profile (no external libs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa9127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'].value_counts(normalize=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f648e83b",
   "metadata": {},
   "source": [
    "**Step 3: Plot distributions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df['age'].hist(bins=20)\n",
    "plt.title('Age Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e3a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x='sessions', y='avg_session_sec', alpha=0.3)\n",
    "plt.title('Sessions vs Avg Session Seconds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ae9fa",
   "metadata": {},
   "source": [
    "**Step 4: Reproducibility stamp**\n",
    "\n",
    "- **Seed:** 42\n",
    "- **Versions:** See prologue cell output\n",
    "- **DATA_DIR:** `./data` (set via `%env` magic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9dae7",
   "metadata": {},
   "source": [
    "### B3. Export artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a304f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist CSV and a compact Parquet for downstream steps\n",
    "import os\n",
    "os.makedirs(os.getenv('DATA_DIR', './data'), exist_ok=True)\n",
    "\n",
    "out_csv = os.path.join(os.environ['DATA_DIR'], 'mini_eda_users.csv')\n",
    "out_parquet = os.path.join(os.environ['DATA_DIR'], 'mini_eda_users.parquet')\n",
    "\n",
    "%time df.to_csv(out_csv, index=False)\n",
    "%time df.to_parquet(out_parquet, index=False, engine='fastparquet')\n",
    "\n",
    "out_csv, out_parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a43848",
   "metadata": {},
   "source": [
    "**Artifact paths:**\n",
    "\n",
    "- CSV: `./data/mini_eda_users.csv`\n",
    "- Parquet: `./data/mini_eda_users.parquet`\n",
    "\n",
    "These will be used in later labs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bb9964",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part C — Wrap‑Up\n",
    "\n",
    "### Reflection Questions:\n",
    "\n",
    "1. **When would you prefer a view (`ravel`, `reshape`) over a copy (`flatten`) and why?**\n",
    "   \n",
    "   *Your answer:* Prefer views when you need to conserve memory and ensure changes propagate to the original array. Views are more performant since they don't copy data. Use copies only when you need independent data that won't affect the original.\n",
    "\n",
    "2. **What's an example where pure‑Python loops might still be acceptable?**\n",
    "   \n",
    "   *Your answer:* Pure-Python loops are acceptable for small datasets, complex control flow that can't be vectorized, or when readability is more important than performance (e.g., one-time scripts, prototyping).\n",
    "\n",
    "3. **Which Jupyter magic would you use to:**\n",
    "   - **(a) Benchmark two approaches:** `%timeit` for micro-benchmarks with averaged results\n",
    "   - **(b) Hide verbose output:** `%%capture` to suppress cell output\n",
    "   - **(c) Ensure figures render inline in exported HTML:** `%matplotlib inline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f658e69d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Final Thoughts\n",
    "\n",
    "- **Confusion between `ravel` vs `flatten`:** Remember that `ravel` returns a view when possible (changes affect original), while `flatten` always returns a copy (independent data).\n",
    "- **`%time` vs `%timeit`:** Use `%time` for single-run timing, `%timeit` for averaged benchmarks.\n",
    "- **Memory estimates for lists:** These are approximate due to Python object overhead vs contiguous NumPy buffers.\n",
    "\n",
    "---\n",
    "\n",
    "## Solution Snippets (reference)\n",
    "\n",
    "**Why NumPy faster?**\n",
    "\n",
    "- Contiguous memory + vectorized C/Fortran loops reduce Python interpreter overhead; fewer allocations; better CPU cache locality.\n",
    "\n",
    "**View vs copy demo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0080ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(6)\n",
    "x2 = x.reshape(2,3)\n",
    "r = x2.ravel()\n",
    "f = x2.flatten()\n",
    "\n",
    "x2[0,0] = 999\n",
    "assert x[0] == 999 and r[0] == 999    # view tracks source\n",
    "assert f[0] != 999                     # copy is independent\n",
    "print(\"View vs Copy demo passed!\")\n",
    "print(f\"x[0] = {x[0]}, r[0] = {r[0]}, f[0] = {f[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457d5a0a",
   "metadata": {},
   "source": [
    "**Magics mapping:**\n",
    "\n",
    "- Benchmark: `%timeit` (and `%%time` for single‑run cells)\n",
    "- Hide output: `%%capture`\n",
    "- Inline plots: `%matplotlib inline`\n",
    "- Re-run code after edits to imported modules: `%load_ext autoreload; %autoreload 2`\n",
    "\n",
    "**Speedup expectation:** On typical laptops, `np_array.sum()` ≫ `sum(py_list)`; vectorized square vs loop often yields **10–100×** depending on hardware."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
