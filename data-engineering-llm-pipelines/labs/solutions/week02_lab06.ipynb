{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7add08b",
   "metadata": {},
   "source": [
    "# Lab 06 Solution â€” GroupBy & Joins\n",
    "\n",
    "**Focus Area:** Turning messy raw data into consistent, joined datasets by using `groupby` aggregations and join patterns (inner/left/outer)\n",
    "\n",
    "---\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Use `groupby().agg(...)` to compute perâ€‘key metrics (mean, sum, count, nunique) with **named aggregations**.\n",
    "2. Choose the correct **join** (inner/left/outer) for a question, and verify cardinality with `validate=`.\n",
    "3. Diagnose join pitfalls: duplicated keys (fanâ€‘out), missing keys (antiâ€‘join), and column suffix collisions.\n",
    "4. Build tidy aggregates for downstream LLM prompts/features and persist results to Parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f764cfb6",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "Import required libraries and create sample datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d819a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"pandas version: {pd.__version__}\")\n",
    "print(f\"numpy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825957c",
   "metadata": {},
   "source": [
    "### Create Sample Data\n",
    "\n",
    "If you don't have artifacts from previous labs, we'll synthesize mini tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276cb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample orders dataset\n",
    "orders = pd.DataFrame({\n",
    "    'OrderID': [1, 2, 3, 4, 5, 6],\n",
    "    'CustomerID': ['ALFKI', 'ANATR', 'ANTON', 'ALFKI', 'BERGS', 'CHOPS'],\n",
    "    'ShipCountry': ['USA', 'DE', 'USA', 'USA', 'SE', 'SG'],\n",
    "    'Freight': [32.1, 12.0, 5.0, 50.0, 80.0, 22.0]\n",
    "})\n",
    "\n",
    "# Create sample customers dataset\n",
    "customers = pd.DataFrame({\n",
    "    'CustomerID': ['ALFKI', 'ANATR', 'ANTON', 'BONAP', 'BERGS'],\n",
    "    'CompanyName': ['Alfreds', 'Ana Trujillo', 'Antonio Moreno', 'Bon app', 'Berglunds'],\n",
    "    'Country': ['Germany', 'Mexico', 'Mexico', 'France', 'Sweden']\n",
    "})\n",
    "\n",
    "print(\"Orders Dataset:\")\n",
    "display(orders.head())\n",
    "print(\"\\nCustomers Dataset:\")\n",
    "display(customers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa376261",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A â€” GroupBy Fundamentals & Named Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c4d2c4",
   "metadata": {},
   "source": [
    "### A1. Basic aggregates\n",
    "\n",
    "Per ShipCountry: count orders, mean freight, and total freight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per ShipCountry: orders, mean freight, total freight\n",
    "agg_country = (\n",
    "    orders\n",
    "    .groupby('ShipCountry', as_index=False)\n",
    "    .agg(\n",
    "        orders=('OrderID', 'count'),\n",
    "        freight_mean=('Freight', 'mean'),\n",
    "        freight_sum=('Freight', 'sum')\n",
    "    )\n",
    "    .sort_values('orders', ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Aggregates by Ship Country:\")\n",
    "display(agg_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7292a",
   "metadata": {},
   "source": [
    "### A2. Multiple keys & nunique\n",
    "\n",
    "Per (ShipCountry, CustomerID): count orders and distinct customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569d8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per (ShipCountry, CustomerID): count & distinct orders\n",
    "agg_cc = (\n",
    "    orders\n",
    "    .groupby(['ShipCountry', 'CustomerID'], as_index=False)\n",
    "    .agg(\n",
    "        n_orders=('OrderID', 'count'),\n",
    "        n_cust=('CustomerID', 'nunique')\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Aggregates by Ship Country and Customer ID:\")\n",
    "display(agg_cc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a988ab",
   "metadata": {},
   "source": [
    "### A3. `size` vs `count` and missing values\n",
    "\n",
    "Understanding the difference: `size` counts rows, `count` ignores NaN in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c001e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size counts rows; count ignores NaN in the column\n",
    "orders_with_nulls = orders.assign(Maybe=None)\n",
    "\n",
    "print(\"Using .size() - counts all rows including NaN:\")\n",
    "size_result = orders_with_nulls.groupby('ShipCountry').size()\n",
    "display(size_result)\n",
    "\n",
    "print(\"\\nUsing .count() - ignores NaN values:\")\n",
    "count_result = orders_with_nulls.groupby('ShipCountry')['Maybe'].count()\n",
    "display(count_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce829ee9",
   "metadata": {},
   "source": [
    "**Checkpoint:** When would you choose `size` vs `count`?\n",
    "\n",
    "- Use `size()` when you want to count all rows in each group, regardless of missing values\n",
    "- Use `count()` when you want to count only non-null values in a specific column\n",
    "- `size()` returns the number of rows in each group\n",
    "- `count()` returns the number of non-null values in each group for the specified column(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a9808",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part B â€” Join Patterns & Cardinality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a1b6d7",
   "metadata": {},
   "source": [
    "### B1. Inner vs Left vs Outer (visual & code)\n",
    "\n",
    "Compare different join types and their effects on the resulting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec17225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different join types\n",
    "inner = orders.merge(customers, on='CustomerID', how='inner', validate='many_to_one')\n",
    "left = orders.merge(customers, on='CustomerID', how='left', validate='many_to_one')\n",
    "outer = orders.merge(customers, on='CustomerID', how='outer')\n",
    "\n",
    "print(f\"Original orders: {len(orders)} rows\")\n",
    "print(f\"Inner join: {len(inner)} rows\")\n",
    "print(f\"Left join: {len(left)} rows\")\n",
    "print(f\"Outer join: {len(outer)} rows\")\n",
    "\n",
    "print(\"\\nInner join result (only matching keys):\")\n",
    "display(inner)\n",
    "\n",
    "print(\"\\nLeft join result (all orders, even without matching customer):\")\n",
    "display(left)\n",
    "\n",
    "print(\"\\nOuter join result (all keys from both sides):\")\n",
    "display(outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133363f3",
   "metadata": {},
   "source": [
    "**Join Type Explanation:**\n",
    "\n",
    "- **Inner:** Keep only matching `CustomerID` on both sides (typical for ordersâ†”customers when analyzing realized orders)\n",
    "- **Left:** Keep all orders even if customer row is missing (good for data quality checks / antiâ€‘join)\n",
    "- **Outer:** Keep all keys from both sides (useful for audits, rare in production metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a848a17",
   "metadata": {},
   "source": [
    "### B2. Antiâ€‘join & keys that didn't match\n",
    "\n",
    "Find orders without a matching customer (data quality check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc40cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders without a matching customer (left rows with NaN on right)\n",
    "anti = left[left['CompanyName'].isna()][['OrderID', 'CustomerID']]\n",
    "\n",
    "print(\"Orders without matching customers (anti-join):\")\n",
    "display(anti)\n",
    "\n",
    "if len(anti) > 0:\n",
    "    print(f\"\\nFound {len(anti)} order(s) without matching customer records!\")\n",
    "else:\n",
    "    print(\"\\nAll orders have matching customer records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae6fcda",
   "metadata": {},
   "source": [
    "**Checkpoint:** What business question would left join answer that inner wouldn't?\n",
    "\n",
    "A left join helps answer:\n",
    "- \"Are there orders in our system from customers that don't exist in our customer table?\"\n",
    "- \"What is the data quality issue rate (orphaned orders)?\"\n",
    "- \"Do we have referential integrity problems?\"\n",
    "\n",
    "Inner join would silently drop these problematic records, hiding data quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26697630",
   "metadata": {},
   "source": [
    "### B3. Guard against fanâ€‘out (duplicated keys)\n",
    "\n",
    "Use `validate=` to catch unexpected cardinality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90271608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce a duplicate key to illustrate\n",
    "cust_dupe = pd.concat([customers, customers.iloc[[0]]], ignore_index=True)\n",
    "\n",
    "print(\"Customer data with duplicated key:\")\n",
    "display(cust_dupe)\n",
    "\n",
    "print(\"\\nAttempting merge with validate='many_to_one':\")\n",
    "try:\n",
    "    result = orders.merge(cust_dupe, on='CustomerID', how='inner', validate='many_to_one')\n",
    "    display(result)\n",
    "except Exception as e:\n",
    "    print(f\"âœ“ Validation caught the issue: {e}\")\n",
    "    print(\"\\nThis prevents accidental fan-out joins that would duplicate rows!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53c372",
   "metadata": {},
   "source": [
    "**Validation Options:**\n",
    "- `validate='one_to_one'` - Both keys must be unique\n",
    "- `validate='one_to_many'` - Left key unique, right can have duplicates\n",
    "- `validate='many_to_one'` - Right key unique, left can have duplicates\n",
    "- `validate='many_to_many'` - Both sides can have duplicates (use with caution!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d7e82",
   "metadata": {},
   "source": [
    "### B4. Column name collisions & suffixes\n",
    "\n",
    "Handle cases where both sides share column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13114b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When both sides share column names (e.g., Country), rename or use suffixes\n",
    "# Option 1: Rename before merge\n",
    "joined = orders.merge(\n",
    "    customers.rename(columns={'Country': 'CustCountry'}),\n",
    "    on='CustomerID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(\"Join with renamed column to avoid collision:\")\n",
    "display(joined.filter(items=['CustomerID', 'ShipCountry', 'CustCountry']).head())\n",
    "\n",
    "# Option 2: Use suffixes parameter\n",
    "# Note: This would be needed if we didn't rename and had conflicting column names\n",
    "print(\"\\nAlternatively, you can use suffixes parameter for automatic renaming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e754cf2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part C â€” Endâ€‘toâ€‘End Mini Task: Customer Segments & Country Rollups\n",
    "\n",
    "> Goal: Build perâ€‘customer metrics and join to customer attributes for LLMâ€‘ready features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9881d7c8",
   "metadata": {},
   "source": [
    "### C1. Perâ€‘customer aggregates\n",
    "\n",
    "Calculate metrics for each customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-customer aggregates\n",
    "per_cust = (\n",
    "    orders\n",
    "    .groupby('CustomerID', as_index=False)\n",
    "    .agg(\n",
    "        n_orders=('OrderID', 'count'),\n",
    "        freight_mean=('Freight', 'mean'),\n",
    "        freight_sum=('Freight', 'sum')\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Per-customer aggregates:\")\n",
    "display(per_cust)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b347901",
   "metadata": {},
   "source": [
    "### C2. Join with customers (inner vs left) and create segments\n",
    "\n",
    "Enrich customer metrics with customer attributes and create spend segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59943907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with customers using different strategies\n",
    "per_cust_inner = per_cust.merge(customers, on='CustomerID', how='inner', validate='one_to_one')\n",
    "per_cust_left = per_cust.merge(customers, on='CustomerID', how='left', validate='one_to_one')\n",
    "\n",
    "print(f\"Inner join: {len(per_cust_inner)} customers\")\n",
    "print(f\"Left join: {len(per_cust_left)} customers\")\n",
    "\n",
    "# Create spend segments\n",
    "bins = [0, 20, 50, np.inf]\n",
    "labels = ['low', 'mid', 'high']\n",
    "seg = pd.cut(per_cust_inner['freight_sum'], bins=bins, labels=labels, right=False)\n",
    "per_cust_inner = per_cust_inner.assign(spend_segment=seg)\n",
    "\n",
    "print(\"\\nPer-customer data with spend segments:\")\n",
    "display(per_cust_inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bef6df",
   "metadata": {},
   "source": [
    "### C3. Country rollup for reporting\n",
    "\n",
    "Aggregate metrics at the country level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d394b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country rollup for reporting\n",
    "country_rollup = (\n",
    "    per_cust_inner\n",
    "    .groupby('Country', as_index=False)\n",
    "    .agg(\n",
    "        customers=('CustomerID', 'count'),\n",
    "        orders=('n_orders', 'sum'),\n",
    "        freight_sum=('freight_sum', 'sum')\n",
    "    )\n",
    "    .sort_values('orders', ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Country rollup:\")\n",
    "display(country_rollup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e56c3",
   "metadata": {},
   "source": [
    "**Checkpoint:** Which join choice (inner/left) makes more sense for this segment report and why?\n",
    "\n",
    "For a **segment report**, **inner join** is preferred because:\n",
    "- We want to analyze only customers who have complete information\n",
    "- Segments require customer attributes (like Country) to be meaningful\n",
    "- Incomplete customer records would create misleading segments\n",
    "- This is about analyzing realized, valid business relationships\n",
    "\n",
    "**Left join** would be better if:\n",
    "- We wanted to identify data quality issues\n",
    "- We needed to report on ALL orders regardless of customer data completeness\n",
    "- We were doing an audit or diagnostic report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db355366",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part D â€” Bonus (Optional) â€” Use partitioned `orders` Parquet\n",
    "\n",
    "If you have artifacts from previous labs, load and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054ccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for partitioned parquet files from previous labs\n",
    "p = Path('artifacts/parquet/orders')\n",
    "\n",
    "if p.exists():\n",
    "    print(f\"Found partitioned parquet directory: {p}\")\n",
    "    files = sorted(p.glob('shipcountry=*.parquet'))\n",
    "    print(f\"Found {len(files)} partition files\")\n",
    "    \n",
    "    if files:\n",
    "        # Load all partitions\n",
    "        df = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)\n",
    "        print(f\"\\nLoaded {len(df)} rows from partitioned data\")\n",
    "        \n",
    "        # Repeat per-customer aggregates on larger dataset\n",
    "        per_cust_bonus = (\n",
    "            df\n",
    "            .groupby('CustomerID', as_index=False)\n",
    "            .agg(\n",
    "                n_orders=('OrderID', 'count'),\n",
    "                freight_mean=('Freight', 'mean'),\n",
    "                freight_sum=('Freight', 'sum')\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print(\"\\nPer-customer aggregates from partitioned data:\")\n",
    "        display(per_cust_bonus.head(3))\n",
    "    else:\n",
    "        print(\"No partition files found in the directory\")\n",
    "else:\n",
    "    print(f\"Partitioned parquet directory not found: {p}\")\n",
    "    print(\"Skipping bonus section - using sample data from earlier sections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187632e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part E â€” Wrapâ€‘Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622c0948",
   "metadata": {},
   "source": [
    "### Summary & Key Learnings\n",
    "\n",
    "#### 1. When to use Inner vs Left joins\n",
    "\n",
    "**Inner join is preferred when:**\n",
    "- Analyzing realized business transactions (e.g., orders with valid customers)\n",
    "- Building reports/metrics that require complete information from both sides\n",
    "- Creating customer segments where all attributes must be present\n",
    "- Example: \"Calculate total revenue by customer country\" - requires valid customer records\n",
    "\n",
    "**Left join is required when:**\n",
    "- Performing data quality checks (finding orphaned records)\n",
    "- Ensuring no data loss when preserving all records from the primary table\n",
    "- Anti-join patterns to find missing relationships\n",
    "- Example: \"Find all orders that don't have matching customer records\" - reveals data integrity issues\n",
    "\n",
    "#### 2. Using validate= to catch fan-out\n",
    "\n",
    "The `validate=` parameter prevents accidental data duplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c0d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Catch fan-out before it pollutes metrics\n",
    "print(\"Safe merge with cardinality validation:\")\n",
    "print(\"\"\"\\n# This will catch if customers table has duplicate CustomerIDs\n",
    "safe_join = orders.merge(\n",
    "    customers,\n",
    "    on='CustomerID',\n",
    "    how='inner',\n",
    "    validate='many_to_one'  # Orders: many, Customers: one (unique)\n",
    ")\\n\"\"\")\n",
    "\n",
    "print(\"Without validation, a duplicate in customers would:\")\n",
    "print(\"  - Silently duplicate order rows\")\n",
    "print(\"  - Inflate revenue/freight metrics\")\n",
    "print(\"  - Create incorrect aggregate counts\")\n",
    "print(\"\\nWith validation, you get an immediate error message!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855917a",
   "metadata": {},
   "source": [
    "#### 3. Export final datasets to Parquet\n",
    "\n",
    "Save our processed datasets for downstream labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ef60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "out = Path('artifacts/clean')\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Export per-customer data\n",
    "per_cust_path = out / 'per_customer.parquet'\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(per_cust_inner, preserve_index=False),\n",
    "    per_cust_path\n",
    ")\n",
    "print(f\"âœ“ Exported per-customer data to: {per_cust_path}\")\n",
    "\n",
    "# Export country rollup\n",
    "country_path = out / 'country_rollup.parquet'\n",
    "pq.write_table(\n",
    "    pa.Table.from_pandas(country_rollup, preserve_index=False),\n",
    "    country_path\n",
    ")\n",
    "print(f\"âœ“ Exported country rollup to: {country_path}\")\n",
    "\n",
    "# Verify files were created\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"  per_customer.parquet: {per_cust_path.stat().st_size} bytes\")\n",
    "print(f\"  country_rollup.parquet: {country_path.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17216863",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls & How to Avoid Them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1970bf2",
   "metadata": {},
   "source": [
    "### 1. Using `count` vs `size` incorrectly\n",
    "\n",
    "- `count()` skips NaN in the counted column\n",
    "- `size()` counts all rows regardless of NaN values\n",
    "- Choose based on whether you want to include/exclude missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09c888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration\n",
    "demo_df = pd.DataFrame({\n",
    "    'group': ['A', 'A', 'B', 'B'],\n",
    "    'value': [1, None, 2, 3]\n",
    "})\n",
    "\n",
    "print(\"Demo data with NaN:\")\n",
    "display(demo_df)\n",
    "\n",
    "print(\"\\n.size() - counts all rows:\")\n",
    "display(demo_df.groupby('group').size())\n",
    "\n",
    "print(\"\\n.count() - ignores NaN:\")\n",
    "display(demo_df.groupby('group')['value'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc1475",
   "metadata": {},
   "source": [
    "### 2. Forgetting `validate=` and accidentally creating a fanâ€‘out join\n",
    "\n",
    "Always use `validate=` when you know the expected cardinality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best practices for validate parameter:\")\n",
    "print(\"\"\"\\n1. Orders â†’ Customers: validate='many_to_one'\n",
    "   (many orders per customer, one customer record)\n",
    "\n",
    "2. Customer â†’ Orders: validate='one_to_many'\n",
    "   (one customer, many possible orders)\n",
    "\n",
    "3. Order â†’ OrderDetails: validate='one_to_many'\n",
    "   (one order, many line items)\n",
    "\n",
    "4. User â†’ Profile: validate='one_to_one'\n",
    "   (one user, one profile)\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005cdf27",
   "metadata": {},
   "source": [
    "### 3. Relying on outer joins for metrics\n",
    "\n",
    "- **Outer joins** often inflate counts and create confusion\n",
    "- Prefer **inner joins** for realized facts (actual transactions)\n",
    "- Use **left joins** for QA/auditing purposes\n",
    "- Reserve **outer joins** for specific reconciliation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cde0768",
   "metadata": {},
   "source": [
    "### 4. Column name collisions\n",
    "\n",
    "Two strategies to handle conflicting column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a533cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Strategy 1: Rename columns before merge\")\n",
    "print(\"\"\"\\ncustomers.rename(columns={'Country': 'CustCountry'})\\n\"\"\")\n",
    "\n",
    "print(\"Strategy 2: Use suffixes parameter\")\n",
    "print(\"\"\"\\ndf.merge(other, on='key', suffixes=('_left', '_right'))\\n\"\"\")\n",
    "\n",
    "print(\"Recommendation: Rename before merge for clarity and explicit control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad6c589",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution Reference\n",
    "\n",
    "### Named aggregations pattern:\n",
    "```python\n",
    "orders.groupby('CustomerID', as_index=False).agg(\n",
    "    n_orders=('OrderID', 'count'),\n",
    "    freight_mean=('Freight', 'mean')\n",
    ")\n",
    "```\n",
    "\n",
    "### Cardinality checks:\n",
    "```python\n",
    "orders.merge(\n",
    "    customers,\n",
    "    on='CustomerID',\n",
    "    how='inner',\n",
    "    validate='many_to_one'\n",
    ")\n",
    "```\n",
    "\n",
    "### Antiâ€‘join pattern:\n",
    "```python\n",
    "orders.merge(\n",
    "    customers,\n",
    "    on='CustomerID',\n",
    "    how='left',\n",
    "    indicator=True\n",
    ").query(\"_merge == 'left_only'\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6b96d8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lab Complete! ðŸŽ‰\n",
    "\n",
    "You have successfully:\n",
    "- âœ“ Mastered groupby with named aggregations\n",
    "- âœ“ Understood different join types and their use cases\n",
    "- âœ“ Implemented cardinality validation to prevent data quality issues\n",
    "- âœ“ Built customer segments and country rollups\n",
    "- âœ“ Exported clean datasets for downstream use\n",
    "\n",
    "The exported Parquet files in `artifacts/clean/` are ready for use in subsequent labs!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
