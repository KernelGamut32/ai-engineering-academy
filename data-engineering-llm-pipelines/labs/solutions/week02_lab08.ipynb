{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147224ee",
   "metadata": {},
   "source": [
    "# Lab 08 — Why Schema Validation in ML/LLM Pipelines\n",
    "\n",
    "**Focus Area:** Why schema validation — catching upstream drift; protecting training/eval\n",
    "\n",
    "> This lab is the *why* and *show‑me* for validation. You'll simulate upstream changes (types, ranges, unexpected categories) and see how a light schema gate prevents bad data from reaching LLM‑adjacent stages.\n",
    "\n",
    "---\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Explain the difference between **structural drift** (columns/types) and **semantic drift** (values/ranges/categories), and why each harms LLM workflows.\n",
    "2. Add a **pre‑flight validation gate** that fails fast with actionable messages.\n",
    "3. Use a **minimal Pandera schema** (or Pydantic model per row) to enforce types, ranges, and categorical sets.\n",
    "4. Capture **human‑readable failure reports** for debugging, CI, and incident triage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859bf74",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `pandera`, `pydantic`, `pyarrow` installed.  \n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "- Artifacts from previous labs (optional but recommended): `artifacts/clean/per_customer.parquet` or `users_clean.parquet`  \n",
    "\n",
    "**Start a notebook:** `week02_lab08.ipynb`\n",
    "\n",
    "If you don't have prior artifacts, synthesize a small frame now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b34a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "rng = np.random.default_rng(42)\n",
    "users2 = pd.DataFrame({\n",
    "    'CustomerID': [f'C{i:05d}' for i in range(300)],\n",
    "    'country_norm': rng.choice(['USA','DE','SG','BR'], size=300, p=[.55,.2,.15,.1]),\n",
    "    'age': rng.integers(16, 80, size=300).astype('int64'),\n",
    "    'ltv_usd': np.round(np.clip(rng.lognormal(3.0, 0.7, size=300), 0, 5e4), 2),\n",
    "    'is_adult': (rng.integers(16, 80, size=300) >= 18),\n",
    "    'is_high_value': rng.random(300) > 0.85,\n",
    "})\n",
    "users2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70a8da9",
   "metadata": {},
   "source": [
    "## Part A — What can go wrong, concretely?\n",
    "\n",
    "In LLM/ML pipelines, silent data drift can:\n",
    "\n",
    "- **Break transforms** (e.g., `to_datetime` fails after a type flip from string→int).\n",
    "- **Bias metrics** (e.g., new country labels split a cohort: `U.S.A.` appears again).\n",
    "- **Explode tokens/costs** (e.g., unexpectedly long text fields; numeric → string inflation).\n",
    "- **Poison eval/train** (e.g., negative prices; out‑of‑range ages; missing required keys).\n",
    "\n",
    "**Exercise:** Create 3 synthetic drifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37a157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "broken = users2.copy()\n",
    "# 1) Structural drift: age becomes string for some rows\n",
    "broken.loc[broken.index[:20], 'age'] = broken.loc[broken.index[:20], 'age'].astype(str)\n",
    "# 2) Semantic drift: country label out of policy\n",
    "broken.loc[10:15, 'country_norm'] = ['U.S.A.','United States','usa','US','USA','USA']\n",
    "# 3) Range drift: negative ltv sneaks in\n",
    "broken.loc[50:55, 'ltv_usd'] = [-10, -5, -1, 0, 1, 2]\n",
    "broken.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff0daf",
   "metadata": {},
   "source": [
    "## Part B — Minimal Pandera schema as a gate\n",
    "\n",
    "We'll define a small DataFrame schema to catch the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandera\n",
    "\n",
    "import pandera.pandas as pa\n",
    "from pandera import Column, Check\n",
    "\n",
    "Schema = pa.DataFrameSchema({\n",
    "    'CustomerID': Column(object, nullable=False),\n",
    "    'country_norm': Column(object, Check.isin(['USA','DE','SG','BR']), nullable=False),\n",
    "    'age': Column(pa.Int64, Check.in_range(0, 120), nullable=False),\n",
    "    'ltv_usd': Column(float, Check.ge(0), nullable=False),\n",
    "    'is_adult': Column(bool, nullable=False),\n",
    "    'is_high_value': Column(bool, nullable=False),\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77462d51",
   "metadata": {},
   "source": [
    "### B1. Validate clean vs broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae2d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean should pass\n",
    "ok = Schema.validate(users2, lazy=True)\n",
    "print('clean rows:', len(ok))\n",
    "\n",
    "# Broken should fail with a report\n",
    "try:\n",
    "    Schema.validate(broken, lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    report = err.failure_cases\n",
    "    print(report.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358594fd",
   "metadata": {},
   "source": [
    "**Checkpoint:** Inspect `report` to see: wrong dtype (`age`), out‑of‑set categories (`country_norm`), and negative values (`ltv_usd`).\n",
    "\n",
    "### B2. Actionable messages for CI / logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2bf2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize by column + failure type\n",
    "summary = (report\n",
    "           .groupby(['column', 'check'])\n",
    "           .size()\n",
    "           .reset_index(name='failures')\n",
    "           .sort_values('failures', ascending=False))\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5efa45",
   "metadata": {},
   "source": [
    "> **Interpretation:** This summary is what you'd attach to a CI artifact or Slack alert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da89d0e7",
   "metadata": {},
   "source": [
    "## Part C — Row‑level validation with Pydantic (optional)\n",
    "\n",
    "Use Pydantic models when you're validating **per‑row payloads** (e.g., API messages) or writing contracts across services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydantic\n",
    "\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Literal\n",
    "\n",
    "class CustomerRow(BaseModel):\n",
    "    CustomerID: str\n",
    "    country_norm: Literal['USA','DE','SG','BR']\n",
    "    age: int = Field(ge=0, le=120)\n",
    "    ltv_usd: float = Field(ge=0)\n",
    "    is_adult: bool\n",
    "    is_high_value: bool\n",
    "\n",
    "row = users2.iloc[0].to_dict()\n",
    "CustomerRow(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1da8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    CustomerRow(**broken.iloc[12].to_dict())\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72c5cd1",
   "metadata": {},
   "source": [
    "**When to prefer Pydantic:** API boundaries, message queues, microservices. **When to prefer Pandera:** bulk DataFrame validation in ETL/ELT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d01a7d5",
   "metadata": {},
   "source": [
    "## Part D — Pre‑flight gate function + fail‑fast\n",
    "\n",
    "Wrap the schema check in a reusable function that raises a concise, friendly error and writes a CSV report for triage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5288ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def validate_or_raise(df: pd.DataFrame, schema: pa.DataFrameSchema, name: str, out_dir: str = 'artifacts/validation') -> pd.DataFrame:\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        return schema.validate(df, lazy=True)\n",
    "    except pa.errors.SchemaErrors as err:\n",
    "        rep = err.failure_cases\n",
    "        dest = Path(out_dir) / f'{name}_schema_failures.csv'\n",
    "        rep.to_csv(dest, index=False)\n",
    "        # compact message for logs/CI\n",
    "        top = (rep.groupby(['column','check']).size().reset_index(name='n')\n",
    "                 .sort_values('n', ascending=False).head(5).to_dict(orient='records'))\n",
    "        raise RuntimeError(f\"Validation failed for {name}. Top issues: {top}. See {dest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa81d694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "_ = validate_or_raise(users2, Schema, name='users2_clean')\n",
    "try:\n",
    "    _ = validate_or_raise(broken, Schema, name='users2_broken')\n",
    "except RuntimeError as e:\n",
    "    print('\\nGATE BLOCKED ->', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5bc44",
   "metadata": {},
   "source": [
    "## Part E — Wrap‑Up\n",
    "\n",
    "Add a markdown cell and answer:\n",
    "\n",
    "1. Name one structural and one semantic drift you simulated. How would each impact an LLM component downstream?  \n",
    "2. Paste the top 3 failure types from your summary and propose a remediation (fix in source vs transform rule).  \n",
    "3. Where would you place this validation gate in your Day‑1/Day‑2 pipeline, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44128b5a",
   "metadata": {},
   "source": [
    "### Your answers here:\n",
    "\n",
    "**1. Structural and Semantic Drift:**\n",
    "\n",
    "- **Structural drift:** Age column changed from Int64 to string for some rows. This would break downstream operations like numerical aggregations, comparisons, or ML model features that expect numeric input.\n",
    "- **Semantic drift:** Country labels changed to non-standard values ('U.S.A.', 'United States', 'usa', 'US'). This would cause category splits in LLM prompts, create duplicate embeddings for the same entity, and inflate token usage unnecessarily.\n",
    "\n",
    "**2. Top 3 Failure Types:**\n",
    "\n",
    "*(Fill in based on your actual output)*\n",
    "\n",
    "Example:\n",
    "- `age` dtype mismatch: Fix at source by enforcing integer type constraints in upstream system\n",
    "- `country_norm` out of allowed set: Add transform rule to normalize variants before validation\n",
    "- `ltv_usd` negative values: Fix at source by adding database constraint or API validation\n",
    "\n",
    "**3. Validation Gate Placement:**\n",
    "\n",
    "I would place this validation gate:\n",
    "- **Immediately after data ingestion** (Day-1) to fail fast before any transformation or enrichment\n",
    "- **Before feature engineering** (Day-2) to protect ML/LLM components from corrupted inputs\n",
    "- **As a CI/CD check** before promoting data to production storage\n",
    "\n",
    "Why: Early detection minimizes wasted processing, prevents cascading errors, and provides clear diagnostic information at the point of failure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c660596",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Common pitfalls:** Using `object` dtypes everywhere; not distinguishing `structural` vs `semantic` drift; over‑fitting schemas (too strict for expected evolution)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0982abe",
   "metadata": {},
   "source": [
    "## Solution Snippets (reference)\n",
    "\n",
    "**Quick failure roll‑up:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = (report.groupby(['column','check'])\n",
    "           .size().reset_index(name='failures')\n",
    "           .sort_values('failures', ascending=False))\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b837c8ad",
   "metadata": {},
   "source": [
    "**CI‑style assert:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cc881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Schema.validate(users2, lazy=True) is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0b730",
   "metadata": {},
   "source": [
    "**Lightweight allow‑list for categories:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea31c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = {'USA','DE','SG','BR'}\n",
    "viol = set(broken['country_norm']) - allowed\n",
    "viol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b60955e",
   "metadata": {},
   "source": [
    "## Bonus: Real-World Example with Lab Artifacts\n",
    "\n",
    "Let's apply the validation concepts to the actual `per_customer.parquet` file from previous labs to see how schema validation works with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c10677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the real customer data from previous labs\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if the per_customer.parquet file exists\n",
    "artifact_path = Path('artifacts/clean/per_customer.parquet')\n",
    "if artifact_path.exists():\n",
    "    print(f\"✓ Found artifact: {artifact_path}\")\n",
    "    real_customers = pd.read_parquet(artifact_path)\n",
    "    print(f\"Shape: {real_customers.shape}\")\n",
    "    print(f\"Columns: {list(real_customers.columns)}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(real_customers.head())\n",
    "    print(\"\\nData types:\")\n",
    "    print(real_customers.dtypes)\n",
    "else:\n",
    "    print(f\"✗ Artifact not found at {artifact_path}\")\n",
    "    print(\"Available files in artifacts/clean/:\")\n",
    "    clean_dir = Path('artifacts/clean')\n",
    "    if clean_dir.exists():\n",
    "        for f in clean_dir.iterdir():\n",
    "            print(f\"  - {f.name}\")\n",
    "    else:\n",
    "        print(\"  artifacts/clean directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398ca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dynamic schema based on the actual data structure\n",
    "if 'real_customers' in locals() and not real_customers.empty:\n",
    "    print(\"Creating schema based on actual data structure...\")\n",
    "    \n",
    "    # Inspect unique values in categorical columns\n",
    "    categorical_cols = real_customers.select_dtypes(include=['object']).columns\n",
    "    print(f\"\\nCategorical columns: {list(categorical_cols)}\")\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        unique_vals = real_customers[col].unique()\n",
    "        print(f\"{col}: {len(unique_vals)} unique values\")\n",
    "        if len(unique_vals) <= 10:\n",
    "            print(f\"  Values: {list(unique_vals)}\")\n",
    "        else:\n",
    "            print(f\"  Sample: {list(unique_vals[:5])}...\")\n",
    "    \n",
    "    # Check for potential issues\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"POTENTIAL DATA QUALITY ISSUES:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check for null values\n",
    "    nulls = real_customers.isnull().sum()\n",
    "    if nulls.any():\n",
    "        print(\"\\n🚨 Null values detected:\")\n",
    "        for col, count in nulls[nulls > 0].items():\n",
    "            print(f\"  {col}: {count} nulls ({count/len(real_customers)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"\\n✅ No null values found\")\n",
    "    \n",
    "    # Check for negative values in numeric columns\n",
    "    numeric_cols = real_customers.select_dtypes(include=[np.number]).columns\n",
    "    print(f\"\\n📊 Numeric columns: {list(numeric_cols)}\")\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if (real_customers[col] < 0).any():\n",
    "            neg_count = (real_customers[col] < 0).sum()\n",
    "            print(f\"🚨 {col}: {neg_count} negative values\")\n",
    "        else:\n",
    "            print(f\"✅ {col}: No negative values\")\n",
    "    \n",
    "    print(f\"\\n📈 Data summary:\")\n",
    "    print(real_customers.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939b534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Pandera schema for the real customer data\n",
    "if 'real_customers' in locals() and not real_customers.empty:\n",
    "    print(\"Building Pandera schema for real customer data...\\n\")\n",
    "    \n",
    "    # Create schema constraints based on discovered data patterns\n",
    "    real_schema_constraints = {}\n",
    "    \n",
    "    for col in real_customers.columns:\n",
    "        dtype = real_customers[col].dtype\n",
    "        print(f\"Processing {col} ({dtype})...\")\n",
    "        \n",
    "        if pd.api.types.is_object_dtype(dtype):\n",
    "            # For categorical columns, create allow-list from unique values\n",
    "            unique_vals = real_customers[col].dropna().unique()\n",
    "            if len(unique_vals) <= 20:  # Only create strict validation for small sets\n",
    "                real_schema_constraints[col] = Column(object, Check.isin(unique_vals), nullable=real_customers[col].isnull().any())\n",
    "                print(f\"  → Created allow-list with {len(unique_vals)} values\")\n",
    "            else:\n",
    "                real_schema_constraints[col] = Column(object, nullable=real_customers[col].isnull().any())\n",
    "                print(f\"  → Too many values ({len(unique_vals)}), using basic object validation\")\n",
    "        \n",
    "        elif pd.api.types.is_numeric_dtype(dtype):\n",
    "            # For numeric columns, set reasonable range constraints\n",
    "            min_val = real_customers[col].min()\n",
    "            max_val = real_customers[col].max()\n",
    "            \n",
    "            # Build checks based on data characteristics\n",
    "            checks = []\n",
    "            if min_val >= 0:  # If all values are non-negative, enforce that\n",
    "                checks.append(Check.ge(0))\n",
    "                print(f\"  → Added non-negative constraint (min: {min_val})\")\n",
    "            \n",
    "            if max_val < 1000:  # Add upper bound for reasonable ranges\n",
    "                checks.append(Check.le(max_val * 1.1))  # 10% buffer\n",
    "                print(f\"  → Added upper bound: {max_val * 1.1}\")\n",
    "            \n",
    "            real_schema_constraints[col] = Column(dtype, checks, nullable=real_customers[col].isnull().any())\n",
    "        \n",
    "        elif pd.api.types.is_bool_dtype(dtype):\n",
    "            real_schema_constraints[col] = Column(bool, nullable=real_customers[col].isnull().any())\n",
    "            print(f\"  → Boolean validation\")\n",
    "        \n",
    "        else:\n",
    "            real_schema_constraints[col] = Column(dtype, nullable=real_customers[col].isnull().any())\n",
    "            print(f\"  → Generic validation for {dtype}\")\n",
    "    \n",
    "    # Create the schema\n",
    "    RealCustomerSchema = pa.DataFrameSchema(real_schema_constraints)\n",
    "    print(f\"\\n✅ Created schema with {len(real_schema_constraints)} column validations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50de532a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the schema on the real data\n",
    "if 'RealCustomerSchema' in locals() and 'real_customers' in locals():\n",
    "    print(\"Testing schema validation on real customer data...\\n\")\n",
    "    \n",
    "    try:\n",
    "        validated_data = RealCustomerSchema.validate(real_customers, lazy=True)\n",
    "        print(\"✅ VALIDATION PASSED!\")\n",
    "        print(f\"Successfully validated {len(validated_data)} rows\")\n",
    "    except pa.errors.SchemaErrors as err:\n",
    "        print(\"🚨 VALIDATION FAILED!\")\n",
    "        failures = err.failure_cases\n",
    "        print(f\"Found {len(failures)} validation failures:\")\n",
    "        print(failures.groupby(['column', 'check']).size().reset_index(name='count').head(10))\n",
    "    \n",
    "    # Now let's simulate some data corruption and see how our schema catches it\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SIMULATING DATA CORRUPTION SCENARIOS:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create a corrupted version of real data\n",
    "    corrupted_real = real_customers.copy()\n",
    "    \n",
    "    # Scenario 1: Introduce negative values in a numeric column\n",
    "    if len(real_customers.select_dtypes(include=[np.number]).columns) > 0:\n",
    "        numeric_col = real_customers.select_dtypes(include=[np.number]).columns[0]\n",
    "        corrupted_real.loc[:5, numeric_col] = -999\n",
    "        print(f\"Scenario 1: Added negative values to {numeric_col}\")\n",
    "    \n",
    "    # Scenario 2: Add invalid categories to a categorical column\n",
    "    if len(real_customers.select_dtypes(include=['object']).columns) > 0:\n",
    "        cat_col = real_customers.select_dtypes(include=['object']).columns[0]\n",
    "        corrupted_real.loc[:3, cat_col] = 'INVALID_CATEGORY'\n",
    "        print(f\"Scenario 2: Added invalid category to {cat_col}\")\n",
    "    \n",
    "    # Test the corrupted data\n",
    "    try:\n",
    "        RealCustomerSchema.validate(corrupted_real, lazy=True)\n",
    "        print(\"❌ Schema failed to catch corruption!\")\n",
    "    except pa.errors.SchemaErrors as err:\n",
    "        print(f\"\\n✅ Schema successfully caught {len(err.failure_cases)} corruption issues:\")\n",
    "        failure_summary = (err.failure_cases\n",
    "                          .groupby(['column', 'check'])\n",
    "                          .size()\n",
    "                          .reset_index(name='failures')\n",
    "                          .sort_values('failures', ascending=False))\n",
    "        print(failure_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
