{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f6c2691",
   "metadata": {},
   "source": [
    "# Lab 09 — Pandera & Pydantic Walkthrough\n",
    "\n",
    "**Focus Area:** Column types, constraints (`Check.in_range`, regex), row/DF checks, error handling, CI hooks\n",
    "\n",
    "> This lab is the *how*: you'll author practical schemas with **Pandera** (DataFrame‑level) and **Pydantic** (row/message‑level), wire clear error messages, and add lightweight CI hooks so bad data never reaches downstream LLM steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebacdfb",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Define **column types** and **constraints** in Pandera (range checks, regex/category allow‑lists, cross‑column rules).\n",
    "2. Write **row‑level contracts** with Pydantic and use validators for custom logic.\n",
    "3. Handle validation errors gracefully: produce compact roll‑ups for logs/CI and detailed CSVs for triage.\n",
    "4. Add **CI hooks** (pytest + pre‑commit) that fail fast on drift."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d963a5bd",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `pandera>=0.20`, `pydantic>=2.0`, `pyarrow`, `pytest` (for the CI section).\n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "- Artifacts: Prefer `artifacts/clean/per_customer_enriched.parquet` and `users2_clean.parquet`. If not present, use the synthetic block below.\n",
    "\n",
    "**Start a notebook:** `week02_lab09.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fd2b5",
   "metadata": {},
   "source": [
    "### Synthetic fallback (run only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4395f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(1)\n",
    "users2 = pd.DataFrame({\n",
    "    'CustomerID': [f'C{i:05d}' for i in range(500)],\n",
    "    'country_norm': rng.choice(['USA','DE','SG','BR'], 500, p=[.55,.2,.15,.1]),\n",
    "    'age': rng.integers(16, 80, 500).astype('Int64'),\n",
    "    'ltv_usd': np.round(np.clip(rng.lognormal(3.0, 0.7, 500), 0, 5e5), 2),\n",
    "    'email': [f'user{i}@example.com' for i in range(500)],\n",
    "    'is_adult': True,\n",
    "    'is_high_value': rng.random(500) > 0.9,\n",
    "})\n",
    "users2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b120d4a",
   "metadata": {},
   "source": [
    "## Part A — Pandera DataFrame Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43439893",
   "metadata": {},
   "source": [
    "### A1. Define column types & simple constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e84ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandera as pa\n",
    "from pandera import Column, Check\n",
    "\n",
    "AllowedCountries = ['USA','DE','SG','BR']\n",
    "\n",
    "UsersSchema = pa.DataFrameSchema({\n",
    "    'CustomerID': Column(object, nullable=False, checks=Check.str_matches(r'^C\\d{5}$')),\n",
    "    'country_norm': Column(object, nullable=False, checks=Check.isin(AllowedCountries)),\n",
    "    'age': Column(pa.Int64, nullable=False, checks=Check.in_range(0, 120)),\n",
    "    'ltv_usd': Column(float, nullable=False, checks=Check.ge(0)),\n",
    "    'email': Column(object, nullable=False, checks=Check.str_matches(r'^.+@.+\\..+$')),\n",
    "    'is_adult': Column(bool, nullable=False),\n",
    "    'is_high_value': Column(bool, nullable=False),\n",
    "})\n",
    "\n",
    "clean = UsersSchema.validate(users2, lazy=True)\n",
    "len(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5866c5",
   "metadata": {},
   "source": [
    "### A2. Cross‑column & DataFrame‑wide checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6898194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row-level: if age >= 18 then is_adult must be True\n",
    "UsersSchema = UsersSchema.update_checks({\n",
    "    'is_adult': [\n",
    "        Check(lambda s, df: (~(df['age'] >= 18)) | s, error=\"is_adult must be True when age>=18\")\n",
    "    ]\n",
    "})\n",
    "\n",
    "# DF-level: median ltv_usd must be within a sane band; and all CustomerIDs unique\n",
    "UsersSchema = UsersSchema.add_checks([\n",
    "    pa.Check(lambda df: df['ltv_usd'].median() <= 1e5, element_wise=False, error=\"Median LTV too large\"),\n",
    "    pa.Check(lambda df: df['CustomerID'].is_unique, element_wise=False, error=\"Duplicate CustomerID\")\n",
    "])\n",
    "\n",
    "ok = UsersSchema.validate(clean, lazy=True)\n",
    "ok.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7954168c",
   "metadata": {},
   "source": [
    "### A3. Friendly error reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af6f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Inject a couple of bad rows to see errors\n",
    "    broken = clean.copy()\n",
    "    broken.loc[0, 'age'] = 200\n",
    "    broken.loc[1, 'email'] = 'not-an-email'\n",
    "    UsersSchema.validate(broken, lazy=True)\n",
    "except pa.errors.SchemaErrors as err:\n",
    "    fc = err.failure_cases\n",
    "    rollup = (fc.groupby(['column','check']).size().reset_index(name='n')\n",
    "                .sort_values('n', ascending=False))\n",
    "    display(rollup.head(10))\n",
    "    fc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea65e7",
   "metadata": {},
   "source": [
    "**Checkpoint:** How would you surface `rollup` in CI vs provide `failure_cases` as a CSV for analysts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2716d84",
   "metadata": {},
   "source": [
    "## Part B — Pydantic Row Contracts\n",
    "\n",
    "Use Pydantic for **message boundaries** (e.g., API payloads) or row‑wise validation when building microservices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa5515",
   "metadata": {},
   "source": [
    "### B1. Define a model with field constraints & validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee83f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, EmailStr, ValidationError, field_validator\n",
    "from typing import Literal\n",
    "\n",
    "class CustomerRow(BaseModel):\n",
    "    CustomerID: str = Field(pattern=r'^C\\d{5}$')\n",
    "    country_norm: Literal['USA','DE','SG','BR']\n",
    "    age: int = Field(ge=0, le=120)\n",
    "    ltv_usd: float = Field(ge=0)\n",
    "    email: EmailStr\n",
    "    is_adult: bool\n",
    "    is_high_value: bool\n",
    "\n",
    "    @field_validator('is_adult')\n",
    "    @classmethod\n",
    "    def adult_flag_consistent(cls, v, info):\n",
    "        age = info.data.get('age', None)\n",
    "        if age is not None and age >= 18 and v is False:\n",
    "            raise ValueError('is_adult must be true when age>=18')\n",
    "        return v\n",
    "\n",
    "row = users2.iloc[0].to_dict()\n",
    "CustomerRow(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19108360",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    bad = users2.iloc[1].to_dict() | {'email': 'nope', 'age': 200}\n",
    "    CustomerRow(**bad)\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095df1d9",
   "metadata": {},
   "source": [
    "### B2. Apply to a batch (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2370a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_batch(df):\n",
    "    errors = []\n",
    "    for i, rec in df.head(50).iterrows():  # sample for speed in demo\n",
    "        try:\n",
    "            CustomerRow(**rec.to_dict())\n",
    "        except ValidationError as e:\n",
    "            errors.append({'idx': i, 'error': str(e).split('\\n')[0]})\n",
    "    return pd.DataFrame(errors)\n",
    "\n",
    "validate_batch(users2).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39171c",
   "metadata": {},
   "source": [
    "**Guidance:** Pydantic is great for boundaries; Pandera stays the workhorse for DataFrame ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfee469",
   "metadata": {},
   "source": [
    "## Part C — Error Handling & CI Hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a6e1f",
   "metadata": {},
   "source": [
    "### C1. Utility: validate or raise with artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a453ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def validate_or_artifact(df, schema, name, out_dir='artifacts/validation'):\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        return schema.validate(df, lazy=True)\n",
    "    except pa.errors.SchemaErrors as err:\n",
    "        fc = err.failure_cases\n",
    "        dest = Path(out_dir)/f'{name}_failures.csv'\n",
    "        fc.to_csv(dest, index=False)\n",
    "        # compact summary for console/CI\n",
    "        top = (fc.groupby(['column','check']).size().reset_index(name='n')\n",
    "                .sort_values('n', ascending=False).head(5).to_dict(orient='records'))\n",
    "        raise SystemExit(f\"Validation failed for {name}. Top: {top}. See {dest}\")\n",
    "\n",
    "_ = validate_or_artifact(clean, UsersSchema, 'users2_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d24322d",
   "metadata": {},
   "source": [
    "### C2. Pytest smoke test\n",
    "\n",
    "Create `tests/test_schema.py` (in repo) with:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from lab3b_context import UsersSchema, load_users  # write a tiny loader util in your repo\n",
    "\n",
    "def test_users_schema():\n",
    "    df = load_users()  # returns a pandas DataFrame\n",
    "    try:\n",
    "        UsersSchema.validate(df, lazy=True)\n",
    "    except pa.errors.SchemaErrors as err:\n",
    "        # Fail with a compact roll-up\n",
    "        fc = err.failure_cases\n",
    "        top = (fc.groupby(['column','check']).size().reset_index(name='n')\n",
    "                .sort_values('n', ascending=False).head(5))\n",
    "        assert False, f\"Schema violations:\\n{top.to_string(index=False)}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47eb28",
   "metadata": {},
   "source": [
    "### C3. Pre-commit hook (concept)\n",
    "\n",
    "Add a pre-commit step that runs `pytest -q` on changed data modules or a tiny CLI that loads the latest Parquet and validates. (Instructor repo will provide a ready YAML in the capstone.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8b93e",
   "metadata": {},
   "source": [
    "## Part D — Wrap‑Up\n",
    "\n",
    "Add a markdown cell and answer:\n",
    "\n",
    "1. One Pandera **column** check and one **DF-level** check you authored. Why both?\n",
    "2. Where would you place Pydantic vs Pandera in your pipeline? Give a concrete boundary.\n",
    "3. Paste a compact violation roll-up you'd show in CI.\n",
    "\n",
    "Export the notebook to HTML. If you created a `tests/` file, run `pytest -q` and screenshot the passing test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65227a4b",
   "metadata": {},
   "source": [
    "### Answers\n",
    "\n",
    "**1. Column check and DF-level check:**\n",
    "- **Column check:** `Check.in_range(0, 120)` on the `age` column ensures individual age values are within a realistic range.\n",
    "- **DF-level check:** `pa.Check(lambda df: df['CustomerID'].is_unique, element_wise=False)` ensures uniqueness across the entire dataset.\n",
    "- **Why both?** Column checks validate individual cell values, while DF-level checks enforce constraints that span multiple rows (like uniqueness) or aggregate properties (like median values).\n",
    "\n",
    "**2. Pydantic vs Pandera placement:**\n",
    "- **Pandera:** Use for batch DataFrame validation in ETL pipelines (e.g., validating Parquet files after extraction or transformation).\n",
    "- **Pydantic:** Use at API boundaries for request/response validation, or when processing individual messages/events (e.g., validating incoming JSON payloads in a REST API or message queue consumers).\n",
    "\n",
    "**3. Sample CI violation roll-up:**\n",
    "```\n",
    "  column      check                                n\n",
    "  age         in_range(0, 120)                     1\n",
    "  email       str_matches('^.+@.+\\..+$')           1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d456e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Common Pitfalls\n",
    "\n",
    "- Overly strict schemas\n",
    "- Forgetting nullable dtypes\n",
    "- Using `object` everywhere\n",
    "- Not separating row contracts (Pydantic) from DF contracts (Pandera)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc92062a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Solution Snippets (reference)\n",
    "\n",
    "**Named regex + range checks:**\n",
    "\n",
    "```python\n",
    "Column(object, checks=[Check.str_matches(r'^C\\d{5}$', error='bad id')])\n",
    "Column(pa.Int64, checks=Check.in_range(0,120))\n",
    "```\n",
    "\n",
    "**DF-level uniqueness:**\n",
    "\n",
    "```python\n",
    "pa.Check(lambda df: df['CustomerID'].is_unique, element_wise=False)\n",
    "```\n",
    "\n",
    "**Pydantic field validator:**\n",
    "\n",
    "```python\n",
    "@field_validator('is_adult')\n",
    "def adult_v(cls, v, info):\n",
    "    return v if info.data.get('age',0) < 18 or v else (_ for _ in ()).throw(ValueError('age>=18 requires is_adult'))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
