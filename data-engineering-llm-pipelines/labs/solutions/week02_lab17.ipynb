{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 17 — Few‑Shot Prompting Patterns\n",
    "\n",
    "**Focus Area:** **Few‑shot** prompt construction; consistent exemplar formatting; exemplar selection from prior JSONL artifacts (Labs 13–16)\n",
    "\n",
    "> This lab **builds on Labs 13–16**. You will create a reusable **exemplar bank** from your instruction datasets, learn to format **few‑shot** prompts consistently, and implement simple **similarity‑based selection** to choose the best K shots per query — all **offline**. We’ll use TF‑IDF as a light‑weight stand‑in for embedding similarity.\n",
    "\n",
    "---\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Define **few‑shot prompting** and list cases where it helps vs hurts.  \n",
    "2. Build a curated **exemplar bank** from `{instruction,input,output}` or `{prompt,completion}` JSONL.  \n",
    "3. Implement **consistent templates** (header style / chat style) and enforce schema checks.  \n",
    "4. Select K exemplars using **TF‑IDF cosine similarity** and assemble a final prompt with a deterministic layout.  \n",
    "5. Evaluate prompt length (token proxy) and produce a compact **prompt pack** JSONL for downstream use.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `orjson`, `regex`, `scikit-learn`, `tokenizers` (reuse tiny tokenizer from **Lab 15**)  \n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "- **Artifacts from earlier labs:**  \n",
    "  - `artifacts/jsonl/instruct_trio.jsonl` **and/or** `artifacts/jsonl/instruct_prompt_completion_cleansed.jsonl` (Lab 14)  \n",
    "  - Optional: `artifacts/rag/rag_*_*.jsonl` (Lab 16) for building domain‑matched shots\n",
    "\n",
    "**Start a notebook:** `week02_lab17.ipynb`\n",
    "\n",
    "Create folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "for p in ['artifacts/prompts','artifacts/samples','artifacts/stats']:\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A — What is Few‑Shot Prompting?\n",
    "\n",
    "Add a markdown cell and answer:\n",
    "\n",
    "- Definition: conditioning the model with **formatted exemplars** (input→output pairs) that resemble the target task.  \n",
    "- Helps when: task is under‑specified; model needs **style**/format cues; domain jargon.  \n",
    "- Hurts when: exemplars are **off‑domain**, inconsistent formatting, or too many tokens crowd out problem context.\n",
    "\n",
    "---\n",
    "\n",
    "## Part B — Build an Exemplar Bank\n",
    "\n",
    "### B1. Load from Lab 14 (Trio and/or Prompt‑Completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,\n",
       "                                          instruction input  \\\n",
       " 0  Summarize the key steps from: How to configure...         \n",
       " 1  Summarize the key steps from: Data Retention P...         \n",
       " \n",
       "                                               output  \\\n",
       " 0  Key steps: enable SAML; map claims; verify tim...   \n",
       " 1  Key steps: enable SAML; map claims; verify tim...   \n",
       " \n",
       "                                                 meta  \n",
       " 0  {'doc_id': 'DOC-0484', 'schema_version': 'trio...  \n",
       " 1  {'doc_id': 'DOC-0914', 'schema_version': 'trio...  )"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, orjson, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Prefer Trio; fall back to prompt-completion\n",
    "path_trio = Path('artifacts/jsonl/instruct_trio.jsonl')\n",
    "path_pc   = Path('artifacts/jsonl/instruct_prompt_completion_cleansed.jsonl')\n",
    "\n",
    "rows = []\n",
    "if path_trio.exists():\n",
    "    for line in open(path_trio, 'r', encoding='utf-8'):\n",
    "        o = json.loads(line)\n",
    "        rows.append({\n",
    "            'instruction': o.get('instruction','').strip(),\n",
    "            'input': o.get('input','').strip(),\n",
    "            'output': o.get('output','').strip(),\n",
    "            'meta': o.get('metadata',{})\n",
    "        })\n",
    "elif path_pc.exists():\n",
    "    for line in open(path_pc, 'r', encoding='utf-8'):\n",
    "        o = json.loads(line)\n",
    "        # Heuristic: split PC into instruction/empty input\n",
    "        rows.append({\n",
    "            'instruction': o.get('prompt','').strip(),\n",
    "            'input': '',\n",
    "            'output': o.get('completion','').strip(),\n",
    "            'meta': o.get('metadata',{})\n",
    "        })\n",
    "else:\n",
    "    raise FileNotFoundError('No instruction JSONL found from Lab 14')\n",
    "\n",
    "bank = pd.DataFrame(rows)\n",
    "len(bank), bank.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2. Light cleaning + filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "MIN_OUT_WORDS = 5\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    # Keep meaning-bearing punctuation; just collapse whitespace\n",
    "    return re.sub(r\"\\s+\", \" \", s or '').strip()\n",
    "\n",
    "bank['instruction'] = bank['instruction'].map(norm)\n",
    "bank['input'] = bank['input'].map(norm)\n",
    "bank['output'] = bank['output'].map(norm)\n",
    "\n",
    "bank = bank[(bank['instruction']!='') & (bank['output'].str.split().str.len()>=MIN_OUT_WORDS)].copy()\n",
    "len(bank)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3. Persist as an **exemplar bank** (JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('artifacts/prompts/exemplar_bank.jsonl')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "ex_path = Path('artifacts/prompts/exemplar_bank.jsonl')\n",
    "with ex_path.open('w', encoding='utf-8') as f:\n",
    "    for rec in bank[['instruction','input','output']].to_dict(orient='records'):\n",
    "        f.write(orjson.dumps(rec).decode() + '\\n')\n",
    "ex_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Why separate a curated bank? → Enables auditing, dedupe, and stable few‑shot packs across experiments.\n",
    "\n",
    "---\n",
    "\n",
    "## Part C — Consistent Templates\n",
    "\n",
    "### C1. Header template (Trio style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDR_TMPL = (\n",
    "    \"### Instruction:\\n{instruction}\\n\\n\"\n",
    "    \"### Input:\\n{input}\\n\\n\"\n",
    "    \"### Response:\\n\"\n",
    ")\n",
    "\n",
    "HDR_NO_INPUT_TMPL = (\n",
    "    \"### Instruction:\\n{instruction}\\n\\n\"\n",
    "    \"### Response:\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C2. Chat template (system/user/assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_TMPL = (\n",
    "    \"<system>You are a concise technical assistant.</system>\\n\"\n",
    "    \"<user>Instruction: {instruction}\\n{input_block}</user>\\n\"\n",
    "    \"<assistant>\"\n",
    ")\n",
    "\n",
    "def render_chat(instruction: str, input_text: str) -> str:\n",
    "    input_block = (\"\\nContext: \" + input_text) if input_text else ''\n",
    "    return CHAT_TMPL.format(instruction=instruction, input_block=input_block)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C3. Schema check utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Summarize the key steps from: How to configure SSO (v5). (Overview).',\n",
       " '',\n",
       " 'Key steps: enable SAML; map claims; verify time sync; check audience URI; review settings.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def trio(rec: Dict):\n",
    "    assert 'instruction' in rec and 'output' in rec\n",
    "    return rec['instruction'], rec.get('input',''), rec['output']\n",
    "\n",
    "# Example\n",
    "rec0 = bank.iloc[0].to_dict()\n",
    "trio(rec0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part D — Select K Exemplars via TF‑IDF Similarity\n",
    "\n",
    "### D1. Fit a TF‑IDF model on exemplar instructions (+inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 83)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "corpus = (bank['instruction'] + ' ' + bank['input']).tolist()\n",
    "vec = TfidfVectorizer(min_df=2, max_df=0.9, ngram_range=(1,2))\n",
    "X = vec.fit_transform(corpus)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D2. Exemplar selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Summarize the key steps from: How to configure SSO (v2). (Setup).',\n",
       "  'input': '',\n",
       "  'output': 'Key steps: enable SAML; map claims; verify time sync; check audience URI; review settings.'},\n",
       " {'instruction': 'Summarize the key steps from: How to configure SSO (v3). (Setup).',\n",
       "  'input': '',\n",
       "  'output': 'Key steps: enable SAML; map claims; verify time sync; check audience URI; review settings.'},\n",
       " {'instruction': 'Summarize the key steps from: How to configure SSO (v5). (Setup).',\n",
       "  'input': '',\n",
       "  'output': 'Key steps: enable SAML; map claims; verify time sync; check audience URI; review settings.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def topk_exemplars(query_instruction: str, k: int = 3):\n",
    "    qv = vec.transform([query_instruction])\n",
    "    sims = cosine_similarity(qv, X)[0]\n",
    "    idxs = np.argsort(-sims)[:k]\n",
    "    return bank.iloc[idxs][['instruction','input','output']].to_dict(orient='records')\n",
    "\n",
    "# Smoke test\n",
    "topk_exemplars('Summarize SSO setup steps', k=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D3. Assemble a **few‑shot** prompt (header style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "Summarize the key steps from: How to configure SSO (v2). (FAQ).\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Key steps: enable SAML; map claims; verify time sync; check audience URI; review settings.\n",
      "\n",
      "### Instruction:\n",
      "Summarize the key steps from: How to configure SSO (v2). (Setup).\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Key steps: enable SAML; map claims; verify time sync; check audience URI; review settings.\n",
      "\n",
      "### Instruction:\n",
      "Summarize the key steps from: How to configure SSO (v2). (Overview).\n",
      "\n",
      "### Input:\n",
      "\n",
      "\n",
      "### Response:\n",
      "Key steps: enable SAML; map claims; verify time sync; check audience URI; review s...\n",
      "approx tokens: 693\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# token length proxy to keep under budget\n",
    "_tok = Tokenizer.from_file('artifacts/tokenizer/bytebpe.json')\n",
    "\n",
    "def tok_len(s: str) -> int:\n",
    "    return len(_tok.encode(s).ids)\n",
    "\n",
    "def build_fewshot_prompt(task_instruction: str, task_input: str = '', k: int = 3, mode: str = 'header'):\n",
    "    shots = topk_exemplars(task_instruction, k=k)\n",
    "    parts = []\n",
    "    for ex in shots:\n",
    "        if mode == 'header':\n",
    "            parts.append(HDR_TMPL.format(instruction=ex['instruction'], input=ex.get('input','')) + ex['output'] + \"\\n\\n\")\n",
    "        else:\n",
    "            parts.append(render_chat(ex['instruction'], ex.get('input','')) + ex['output'] + \"\\n\\n\")\n",
    "    # final task\n",
    "    if mode == 'header':\n",
    "        parts.append(HDR_TMPL.format(instruction=task_instruction, input=task_input))\n",
    "    else:\n",
    "        parts.append(render_chat(task_instruction, task_input))\n",
    "    prompt = ''.join(parts)\n",
    "    return prompt, shots\n",
    "\n",
    "p, shots = build_fewshot_prompt('Summarize the key steps for enabling SAML SSO', task_input='AcmeCorp IdP')\n",
    "print(p[:600] + '...')\n",
    "print('approx tokens:', tok_len(p))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D4. Persist as a **prompt pack** JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('artifacts/prompts/fewshot_prompt_pack.jsonl')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import orjson\n",
    "from pathlib import Path\n",
    "\n",
    "pack_path = Path('artifacts/prompts/fewshot_prompt_pack.jsonl')\n",
    "with pack_path.open('w', encoding='utf-8') as f:\n",
    "    # Create a few trial tasks\n",
    "    tasks = [\n",
    "        {'instruction':'Summarize SSO setup steps','input':'', 'k':3},\n",
    "        {'instruction':'Explain rate limits policy','input':'', 'k':4},\n",
    "        {'instruction':'Create a troubleshooting checklist for SAML claims','input':'', 'k':3},\n",
    "    ]\n",
    "    for t in tasks:\n",
    "        prompt, used = build_fewshot_prompt(t['instruction'], t.get('input',''), k=t['k'])\n",
    "        rec = {'prompt': prompt, 'metadata': {'k': t['k'], 'approx_tokens': tok_len(prompt), 'used': used}}\n",
    "        f.write(orjson.dumps(rec).decode() + '\\n')\n",
    "pack_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint:** Inspect the pack; verify consistent formatting across all exemplars and the final instruction block.\n",
    "\n",
    "---\n",
    "\n",
    "## Part E — Wrap‑Up\n",
    "\n",
    "Add a markdown cell and answer:\n",
    "\n",
    "1. In your domain, how many shots (K) strike the best balance between **structure signaling** and **context budget**?  \n",
    "2. When would you prefer **chat** templating vs **header** templating?  \n",
    "3. What filters would you add (e.g., domain tags, language) to keep exemplars **on‑topic**?  \n",
    "4. How will you monitor **prompt drift** (shots degrading over time) as your corpus evolves?\n",
    "\n",
    "Confirm outputs:\n",
    "\n",
    "- `artifacts/prompts/exemplar_bank.jsonl`  \n",
    "- `artifacts/prompts/fewshot_prompt_pack.jsonl`  \n",
    "- Any notes on token budgets and template choice\n",
    "\n",
    "---\n",
    "\n",
    "- **Common pitfalls:** Inconsistent templates; off‑domain or contradictory shots; exceeding token limits; repeating nearly identical examples.\n",
    "\n",
    "---\n",
    "\n",
    "## Solution Snippets (reference)\n",
    "\n",
    "**Switch to chat style few‑shot:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, _ = build_fewshot_prompt(\n",
    "    'Draft a privacy FAQ outline for exports',\n",
    "    mode='chat',\n",
    "    k=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constrain by domain tag (if present in metadata):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter bank by a domain key first\n",
    "mask = bank['instruction'].str.contains('SSO|SAML|claims', case=False, na=False)\n",
    "bank_dom = bank[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Guardrail: drop shots with long outputs (>200 tokens):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = bank[bank['output'].map(lambda s: tok_len(s) <= 200)].copy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
