{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd2bf35",
   "metadata": {},
   "source": [
    "# Lab 10 — Data Profiling at Scale with ydata‑profiling\n",
    "\n",
    "**Focus Area:** Data profiling — summary stats, cardinality, distributions, outlier flags, and integrating reports into review\n",
    "\n",
    "> This lab shows how to generate actionable **profiling reports** for medium–large datasets using **ydata‑profiling**, interpret the outputs (summary stats, high‑cardinality, distributions, correlations, outliers), and integrate those artifacts into your review/CI workflow alongside Pandera/Pydantic gates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaddef3",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Produce a **ProfileReport** (full and minimal) and export it to HTML for team review.\n",
    "2. Interpret key sections: **overview**, **variables**, **interactions**, **correlations**, **missingness**, **alerts** (outliers, skew, high cardinality).\n",
    "3. Extract **machine‑readable metrics** from the report to track drift over time.\n",
    "4. Profile **at scale** using sampling, column subsets, and configuration tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fc598",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `ydata-profiling`, `pyarrow`.\n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "\n",
    "If you don't have artifacts, synthesize a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34da5a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact not found, synthesizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CustomerID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "country_norm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_orders",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "freight_sum",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "freight_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "is_adult",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "is_high_value",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "ref": "924cecff-a95d-4f29-b8e1-6146dcfba3b1",
       "rows": [
        [
         "0",
         "C00000",
         "DE",
         "5",
         "16.81",
         "26.88",
         "True",
         "False"
        ],
        [
         "1",
         "C00001",
         "USA",
         "6",
         "14.5",
         "2.5",
         "True",
         "False"
        ],
        [
         "2",
         "C00002",
         "USA",
         "3",
         "9.76",
         "7.26",
         "True",
         "False"
        ],
        [
         "3",
         "C00003",
         "USA",
         "6",
         "22.98",
         "6.72",
         "True",
         "False"
        ],
        [
         "4",
         "C00004",
         "SG",
         "2",
         "88.19",
         "14.02",
         "True",
         "False"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>country_norm</th>\n",
       "      <th>n_orders</th>\n",
       "      <th>freight_sum</th>\n",
       "      <th>freight_mean</th>\n",
       "      <th>is_adult</th>\n",
       "      <th>is_high_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C00000</td>\n",
       "      <td>DE</td>\n",
       "      <td>5</td>\n",
       "      <td>16.81</td>\n",
       "      <td>26.88</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C00001</td>\n",
       "      <td>USA</td>\n",
       "      <td>6</td>\n",
       "      <td>14.50</td>\n",
       "      <td>2.50</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C00002</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>9.76</td>\n",
       "      <td>7.26</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C00003</td>\n",
       "      <td>USA</td>\n",
       "      <td>6</td>\n",
       "      <td>22.98</td>\n",
       "      <td>6.72</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C00004</td>\n",
       "      <td>SG</td>\n",
       "      <td>2</td>\n",
       "      <td>88.19</td>\n",
       "      <td>14.02</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CustomerID country_norm  n_orders  freight_sum  freight_mean  is_adult  \\\n",
       "0     C00000           DE         5        16.81         26.88      True   \n",
       "1     C00001          USA         6        14.50          2.50      True   \n",
       "2     C00002          USA         3         9.76          7.26      True   \n",
       "3     C00003          USA         6        22.98          6.72      True   \n",
       "4     C00004           SG         2        88.19         14.02      True   \n",
       "\n",
       "   is_high_value  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load existing artifact, or synthesize if not available\n",
    "artifact_path = Path(\"../artifacts/clean/per_customer_enriched.parquet\")\n",
    "\n",
    "if artifact_path.exists():\n",
    "    per_cust_enriched = pd.read_parquet(artifact_path)\n",
    "    print(f\"Loaded {len(per_cust_enriched)} rows from {artifact_path}\")\n",
    "else:\n",
    "    print(\"Artifact not found, synthesizing dataset...\")\n",
    "    rng = np.random.default_rng(0)\n",
    "    N = 50_000\n",
    "    per_cust_enriched = pd.DataFrame({\n",
    "        'CustomerID': [f'C{i:05d}' for i in range(N)],\n",
    "        'country_norm': rng.choice(['USA','DE','SG','BR'], size=N, p=[.58,.18,.16,.08]),\n",
    "        'n_orders': rng.poisson(3, size=N),\n",
    "        'freight_sum': np.round(np.clip(rng.lognormal(3.0, 0.8, size=N), 0, 2e5), 2),\n",
    "        'freight_mean': np.round(np.clip(rng.lognormal(2.5, 0.6, size=N), 0, 1e4), 2),\n",
    "        'is_adult': rng.random(size=N) > 0.1,\n",
    "        'is_high_value': rng.random(size=N) > 0.9,\n",
    "    })\n",
    "\n",
    "per_cust_enriched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774d694",
   "metadata": {},
   "source": [
    "## Part A — Generate a Minimal Profile\n",
    "\n",
    "### A1. Basic report (minimal config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "285af80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy<2.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.11.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (1.15.3)\n",
      "Collecting scipy>=1.11.0\n",
      "  Using cached scipy-1.16.3-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: ydata_profiling in /home/sysadmin/llm_venv/lib/python3.13/site-packages (4.17.0)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3.0,>1.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (2.3.3)\n",
      "Requirement already satisfied: matplotlib<=3.10,>=3.5 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (3.10.0)\n",
      "Requirement already satisfied: pydantic>=2 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (2.12.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (6.0.3)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (3.1.6)\n",
      "Requirement already satisfied: visions<0.8.2,>=0.7.5 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata_profiling) (0.8.1)\n",
      "Requirement already satisfied: minify-html>=0.15.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (0.18.1)\n",
      "Requirement already satisfied: filetype>=1.0.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (1.2.0)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (0.12.5)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (2.32.5)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (4.67.1)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (0.13.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (1.12)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (0.14.5)\n",
      "Requirement already satisfied: typeguard<5,>=3 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (4.4.4)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.3 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (1.9.4)\n",
      "Requirement already satisfied: dacite>=1.8 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (1.9.2)\n",
      "Requirement already satisfied: numba<=0.61,>=0.56.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from ydata_profiling) (0.61.0)\n",
      "Requirement already satisfied: PyWavelets in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from imagehash==4.3.1->ydata_profiling) (1.9.0)\n",
      "Requirement already satisfied: pillow in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from imagehash==4.3.1->ydata_profiling) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from jinja2<3.2,>=2.11.1->ydata_profiling) (3.0.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from matplotlib<=3.10,>=3.5->ydata_profiling) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from numba<=0.61,>=0.56.0->ydata_profiling) (0.44.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata_profiling) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata_profiling) (2025.2)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from phik<0.13,>=0.11.1->ydata_profiling) (1.5.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from requests<3,>=2.24.0->ydata_profiling) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from requests<3,>=2.24.0->ydata_profiling) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from requests<3,>=2.24.0->ydata_profiling) (2025.10.5)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from statsmodels<1,>=0.13.2->ydata_profiling) (1.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.14.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from typeguard<5,>=3->ydata_profiling) (4.15.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata_profiling) (25.4.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata_profiling) (3.5)\n",
      "Requirement already satisfied: puremagic in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from visions<0.8.2,>=0.7.5->visions[type_image_path]<0.8.2,>=0.7.5->ydata_profiling) (1.30)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from pydantic>=2->ydata_profiling) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from pydantic>=2->ydata_profiling) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from pydantic>=2->ydata_profiling) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/sysadmin/llm_venv/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib<=3.10,>=3.5->ydata_profiling) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 25.80it/s]00<00:00,  8.34it/s, Describe variable: is_high_value]\n",
      "Summarize dataset: 100%|██████████| 13/13 [00:00<00:00, 27.01it/s, Completed]                      \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00, 25.41it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 257.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal profile saved to: artifacts/reports/per_customer_minimal.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade \"numpy<2.0\" \"scipy>=1.11.0\" ydata_profiling\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create reports directory if it doesn't exist\n",
    "Path(\"artifacts/reports\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sample data if too large\n",
    "sample = per_cust_enriched.sample(15_000, random_state=42) if len(per_cust_enriched) > 15_000 else per_cust_enriched\n",
    "\n",
    "profile_min = ProfileReport(\n",
    "    sample,\n",
    "    title=\"Per-Customer Enriched — Minimal Profile\",\n",
    "    minimal=True,  # disables heavy calculations (e.g., interactions)\n",
    "    explorative=True,\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "profile_min.to_file(\"artifacts/reports/per_customer_minimal.html\")\n",
    "print(\"Minimal profile saved to: artifacts/reports/per_customer_minimal.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601109a",
   "metadata": {},
   "source": [
    "### A2. Read the overview\n",
    "\n",
    "- **Warnings/Alerts:** high cardinality (e.g., `CustomerID`), skewed distributions (`freight_sum`), zeros inflation.\n",
    "- **Missingness:** ensure expected null rates (should be near 0 post‑cleaning).\n",
    "\n",
    "**Checkpoint:** List 3 alerts the report shows and classify them: quality issue vs expected property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b85d0f",
   "metadata": {},
   "source": [
    "**Analysis of Alerts:**\n",
    "\n",
    "1. **High cardinality in CustomerID** - Expected property (unique identifier)\n",
    "2. **Skewed distribution in freight_sum** - Expected property (log-normal distribution is typical for monetary values)\n",
    "3. **Check for any zero inflation or missing values** - Would be a quality issue if unexpected\n",
    "\n",
    "*(Review the HTML report to identify specific alerts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752c0ae",
   "metadata": {},
   "source": [
    "## Part B — Focused Full Profile (column subset + tuned)\n",
    "\n",
    "### B1. Choose columns and tune config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac774762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 33.27it/s]00<00:01,  6.89it/s, Describe variable: is_high_value]\n",
      "Summarize dataset: 100%|██████████| 25/25 [00:01<00:00, 14.68it/s, Completed]                         \n",
      "Generate report structure: 100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:00<00:00, 13.92it/s]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 308.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focused profile saved to: artifacts/reports/per_customer_focused.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cols = [\"country_norm\",\"n_orders\",\"freight_sum\",\"freight_mean\",\"is_high_value\"]\n",
    "subset = per_cust_enriched[cols].copy()\n",
    "\n",
    "profile_cfg = {\n",
    "    \"title\": \"Per-Customer Enriched — Focused Profile\",\n",
    "    \"dataset\": {\"description\": \"Subset profile for review & CI\"},\n",
    "    \"variables\": {\"descriptions\": {\n",
    "        \"freight_sum\": \"Total freight per customer (currency units)\",\n",
    "        \"freight_mean\": \"Average freight per order\",\n",
    "        \"n_orders\": \"Order count per customer\"\n",
    "    }},\n",
    "    \"correlations\": {\"pearson\": {\"calculate\": True}, \"spearman\": {\"calculate\": True}},\n",
    "    \"missing_diagrams\": {\"heatmap\": True, \"dendrogram\": False},\n",
    "}\n",
    "\n",
    "profile_full = ProfileReport(\n",
    "    subset,\n",
    "    title=profile_cfg[\"title\"],\n",
    "    explorative=True,\n",
    "    minimal=False,\n",
    "    correlations=profile_cfg[\"correlations\"],\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "profile_full.to_file(\"artifacts/reports/per_customer_focused.html\")\n",
    "print(\"Focused profile saved to: artifacts/reports/per_customer_focused.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaf31c",
   "metadata": {},
   "source": [
    "### B2. Interpret variables & correlations\n",
    "\n",
    "- **Variables tab:** check **distributions**, **zeros**, **distinct counts** (cardinality), **outlier flags** for `freight_sum`.\n",
    "- **Correlations:** look for strong positive or negative relationships (e.g., `n_orders` vs `freight_sum`), and verify they are **business‑plausible**.\n",
    "\n",
    "**Checkpoint:** Name one correlation you'd expect and whether the profile confirms it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687929f",
   "metadata": {},
   "source": [
    "**Expected Correlation:**\n",
    "\n",
    "We would expect a **positive correlation between `n_orders` and `freight_sum`** - customers who place more orders should have higher total freight costs. The profile report should confirm this relationship with a positive Pearson/Spearman coefficient.\n",
    "\n",
    "*(Review the Correlations section in the HTML report to verify)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e44ec",
   "metadata": {},
   "source": [
    "## Part C — Extract Metrics Programmatically\n",
    "\n",
    "### C1. Get summary dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1413355c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 50000\n",
      "Variables analyzed: ['country_norm', 'n_orders', 'freight_sum']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000, ['country_norm', 'n_orders', 'freight_sum'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get description object\n",
    "desc = profile_full.get_description()\n",
    "\n",
    "# Access variables directly - they're stored as a dict-like structure\n",
    "n_rows = len(subset)\n",
    "\n",
    "# Extract variable summaries - iterate through the variables\n",
    "var_summaries = {}\n",
    "# Try direct dictionary access first\n",
    "try:\n",
    "    for col in cols:\n",
    "        var_summaries[col] = desc.variables[col]\n",
    "except (TypeError, KeyError):\n",
    "    # Fallback: check if it's an object with attributes\n",
    "    all_vars = dir(desc.variables)\n",
    "    for col in cols:\n",
    "        if col in all_vars:\n",
    "            var_summaries[col] = getattr(desc.variables, col)\n",
    "\n",
    "print(f\"Number of rows: {n_rows}\")\n",
    "print(f\"Variables analyzed: {list(var_summaries.keys())[:3]}\")\n",
    "\n",
    "# Display first few variable names\n",
    "n_rows, list(var_summaries.keys())[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694d18c",
   "metadata": {},
   "source": [
    "### C2. Build a compact drift tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78a7d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to: artifacts/metrics/per_customer_metrics.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_rows': 50000,\n",
       " 'freight_sum_mean': 27.682903800000002,\n",
       " 'freight_sum_std': 26.105907971847415,\n",
       " 'n_orders_mean': 2.99766,\n",
       " 'n_orders_distinct': 13,\n",
       " 'country_cardinality': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Access statistics from variable descriptions (they're dicts, not objects)\n",
    "metrics = {\n",
    "    \"n_rows\": n_rows,\n",
    "    \"freight_sum_mean\": var_summaries['freight_sum']['mean'],\n",
    "    \"freight_sum_std\": var_summaries['freight_sum']['std'],\n",
    "    \"n_orders_mean\": var_summaries['n_orders']['mean'],\n",
    "    \"n_orders_distinct\": var_summaries['n_orders']['n_distinct'],\n",
    "    \"country_cardinality\": var_summaries['country_norm']['n_distinct'],\n",
    "}\n",
    "\n",
    "Path(\"artifacts/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"artifacts/metrics/per_customer_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Metrics saved to: artifacts/metrics/per_customer_metrics.json\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc01837",
   "metadata": {},
   "source": [
    "### C3. Compare to a baseline (simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eca9e4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage differences from baseline:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_rows': 0.111,\n",
       " 'freight_sum_mean': 0.111,\n",
       " 'freight_sum_std': 0.111,\n",
       " 'n_orders_mean': 0.111,\n",
       " 'n_orders_distinct': 0.111,\n",
       " 'country_cardinality': 0.111}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fake baseline and compare for illustration\n",
    "baseline = {k: (v * 0.9 if isinstance(v, (int, float)) else v) for k, v in metrics.items()}\n",
    "\n",
    "def pct_diff(a, b):\n",
    "    return None if b == 0 else (a - b) / b\n",
    "\n",
    "delta = {k: pct_diff(metrics[k], baseline[k]) if isinstance(metrics[k], (int, float)) else None for k in metrics}\n",
    "delta_formatted = {k: round(v, 3) for k, v in delta.items() if v is not None}\n",
    "\n",
    "print(\"Percentage differences from baseline:\")\n",
    "delta_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f45f6c",
   "metadata": {},
   "source": [
    "**Checkpoint:** Which metric movements would trigger investigation (>20% by default)?\n",
    "\n",
    "In this simulated example, all metrics show ~11% change (1/0.9 - 1 ≈ 0.111). In a real scenario:\n",
    "- Changes > 20% in `freight_sum_mean` or `freight_sum_std` would indicate significant data drift\n",
    "- Changes in `country_cardinality` might indicate new markets or data quality issues\n",
    "- Large changes in `n_orders_mean` could signal business shifts or data collection problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fb97d",
   "metadata": {},
   "source": [
    "## Part D — Operate at Scale & Integrate in Review\n",
    "\n",
    "### D1. Tips for biggish data\n",
    "\n",
    "- **Sampling:** `.sample(50_000)` for profiles; keep full data for Pandera validation.\n",
    "- **Disable heavy bits:** `minimal=True` or turn off interactions/correlations you don't need.\n",
    "- **Column subsets:** profile only **review‑critical** columns per PR.\n",
    "- **Persist artifacts:** write to `artifacts/reports/` and link in your PR checklist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8a43a",
   "metadata": {},
   "source": [
    "### D2. Review checklist snippet (add to PR template)\n",
    "\n",
    "- [ ] Profile HTML attached (`per_customer_focused.html`).\n",
    "- [ ] Key metrics JSON updated (`per_customer_metrics.json`).\n",
    "- [ ] Any new high‑cardinality or outlier alerts acknowledged.\n",
    "- [ ] Pandera schema still passes (link to Lab 3B test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f5107",
   "metadata": {},
   "source": [
    "### D3. Wire to CI (concept)\n",
    "\n",
    "- Save `profile.to_file()` output as a CI artifact.\n",
    "- Parse `profile.to_dict()` and **fail** if critical thresholds are exceeded (e.g., null rate, cardinality spike, extreme mean/STD drift).\n",
    "\n",
    "Example CI check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78568c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Metrics validation failed:\n",
      "  country_cardinality: 11.11% change (threshold: 10.0%)\n"
     ]
    }
   ],
   "source": [
    "# Example CI validation function\n",
    "def validate_metrics_for_ci(metrics, baseline, thresholds):\n",
    "    \"\"\"\n",
    "    Validate metrics against baseline with configurable thresholds.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Current metrics dict\n",
    "        baseline: Baseline metrics dict\n",
    "        thresholds: Dict of metric_name -> max_allowed_pct_change\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (passed: bool, failures: list)\n",
    "    \"\"\"\n",
    "    failures = []\n",
    "    \n",
    "    for metric, threshold in thresholds.items():\n",
    "        if metric not in metrics or metric not in baseline:\n",
    "            continue\n",
    "            \n",
    "        current = metrics[metric]\n",
    "        base = baseline[metric]\n",
    "        \n",
    "        if base == 0:\n",
    "            continue\n",
    "            \n",
    "        pct_change = abs((current - base) / base)\n",
    "        \n",
    "        if pct_change > threshold:\n",
    "            failures.append({\n",
    "                'metric': metric,\n",
    "                'current': current,\n",
    "                'baseline': base,\n",
    "                'pct_change': round(pct_change * 100, 2),\n",
    "                'threshold': round(threshold * 100, 2)\n",
    "            })\n",
    "    \n",
    "    return len(failures) == 0, failures\n",
    "\n",
    "# Example usage\n",
    "thresholds = {\n",
    "    'freight_sum_mean': 0.20,  # 20% max change\n",
    "    'freight_sum_std': 0.25,   # 25% max change\n",
    "    'n_orders_mean': 0.15,     # 15% max change\n",
    "    'country_cardinality': 0.10  # 10% max change (new countries should be rare)\n",
    "}\n",
    "\n",
    "passed, failures = validate_metrics_for_ci(metrics, baseline, thresholds)\n",
    "\n",
    "if passed:\n",
    "    print(\"✓ All metrics within acceptable thresholds\")\n",
    "else:\n",
    "    print(\"✗ Metrics validation failed:\")\n",
    "    for failure in failures:\n",
    "        print(f\"  {failure['metric']}: {failure['pct_change']}% change (threshold: {failure['threshold']}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc845a65",
   "metadata": {},
   "source": [
    "## Solution Snippets (reference)\n",
    "\n",
    "### Minimal profile one‑liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9179d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example code - uncomment to run\n"
     ]
    }
   ],
   "source": [
    "# Quick minimal profile for rapid iteration\n",
    "# ProfileReport(df.sample(20_000), minimal=True, explorative=True).to_file(\"../artifacts/reports/df_min.html\")\n",
    "print(\"Example code - uncomment to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09430b",
   "metadata": {},
   "source": [
    "### Turn off heavy interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b53fa317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example code - uncomment to run\n"
     ]
    }
   ],
   "source": [
    "# Profile with correlations but without interactions\n",
    "# ProfileReport(df, minimal=False, correlations={\"pearson\": {\"calculate\": True}}, interactions=None)\n",
    "print(\"Example code - uncomment to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb19ee",
   "metadata": {},
   "source": [
    "### Extract a null‑rate table from dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23809fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null rates by column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'country_norm': 0.0,\n",
       " 'n_orders': 0.0,\n",
       " 'freight_sum': 0.0,\n",
       " 'freight_mean': 0.0,\n",
       " 'is_high_value': 0.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract null rates from profile summary\n",
    "desc = profile_full.get_description()\n",
    "null_rates = {}\n",
    "for col in cols:\n",
    "    if col in desc.variables:\n",
    "        var_dict = desc.variables[col]\n",
    "        null_rates[col] = var_dict.get('p_missing', 0)\n",
    "\n",
    "null_rates_formatted = {k: round(v, 4) for k, v in null_rates.items()}\n",
    "\n",
    "print(\"Null rates by column:\")\n",
    "null_rates_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2523fe8",
   "metadata": {},
   "source": [
    "## Wrap‑Up\n",
    "\n",
    "Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1ceda",
   "metadata": {},
   "source": [
    "### 1. List two alerts flagged by the profile and how you'd mitigate them.\n",
    "\n",
    "**Alert 1: High cardinality in CustomerID**\n",
    "- **Mitigation:** This is expected for a unique identifier. Document as expected behavior and exclude from cardinality warnings in CI. Consider hashing or pseudonymizing if privacy is a concern.\n",
    "\n",
    "**Alert 2: Skewed distribution in freight_sum**\n",
    "- **Mitigation:** Log-normal distributions are common for monetary values. Document this as expected business behavior. Consider using log-scale transformations for ML models. Monitor outliers separately to catch data quality issues.\n",
    "\n",
    "*(Additional alerts to check in the actual report: zeros inflation, extreme values, unexpected missing data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c46fa",
   "metadata": {},
   "source": [
    "### 2. Paste two metrics from your JSON that you will watch in CI and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f13580bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key metrics for CI monitoring:\n",
      "{\n",
      "  \"freight_sum_mean\": 27.682903800000002,\n",
      "  \"country_cardinality\": 4\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Display key metrics to monitor\n",
    "ci_metrics = {\n",
    "    \"freight_sum_mean\": metrics[\"freight_sum_mean\"],\n",
    "    \"country_cardinality\": metrics[\"country_cardinality\"]\n",
    "}\n",
    "\n",
    "print(\"Key metrics for CI monitoring:\")\n",
    "print(json.dumps(ci_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ce8e8",
   "metadata": {},
   "source": [
    "**Metrics to watch in CI:**\n",
    "\n",
    "1. **`freight_sum_mean`**: Monitors the average total freight per customer. Large changes could indicate:\n",
    "   - Pricing changes in the business\n",
    "   - Data quality issues (wrong currency, missing decimals)\n",
    "   - Shift in customer segments\n",
    "   - Threshold: Alert if >20% change from baseline\n",
    "\n",
    "2. **`country_cardinality`**: Tracks the number of distinct countries. Changes could indicate:\n",
    "   - Expansion into new markets (expected if planned)\n",
    "   - Data quality issues (invalid country codes)\n",
    "   - Changes in data collection or normalization logic\n",
    "   - Threshold: Alert if >10% change (should be relatively stable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a51fb1",
   "metadata": {},
   "source": [
    "### 3. Where in the pipeline will you generate and store the profiling report?\n",
    "\n",
    "**Pipeline Integration Strategy:**\n",
    "\n",
    "1. **Generation Points:**\n",
    "   - **Post-cleaning stage:** After data cleaning/enrichment but before loading to production\n",
    "   - **Pre-deployment validation:** As part of CI/CD before promoting to production\n",
    "   - **Scheduled monitoring:** Weekly/monthly for production data drift detection\n",
    "\n",
    "2. **Storage Locations:**\n",
    "   - **HTML Reports:** `artifacts/reports/` directory (versioned or timestamped)\n",
    "   - **Metrics JSON:** `artifacts/metrics/` for programmatic access and CI checks\n",
    "   - **CI Artifacts:** Uploaded as build artifacts in CI/CD system (GitHub Actions, GitLab CI, etc.)\n",
    "   - **Object Storage:** S3/Azure Blob for long-term archival and historical comparison\n",
    "\n",
    "3. **Integration Points:**\n",
    "   - Link HTML reports in PR descriptions for reviewer access\n",
    "   - Automated CI checks parse JSON metrics and fail builds on threshold violations\n",
    "   - Dashboard integration showing metric trends over time\n",
    "   - Alert system for significant drift detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775eb8c",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "- **Running full profiles on multi‑million rows:** Always sample large datasets to reasonable size (10-50k rows)\n",
    "- **Forgetting to sample:** Can cause memory issues and extremely long run times\n",
    "- **Not persisting artifacts:** Reports and metrics should be version-controlled or archived\n",
    "- **Treating expected skew as an error:** Document and accept expected business patterns (log-normal distributions, seasonal effects)\n",
    "- **Over-alerting in CI:** Set appropriate thresholds to avoid alert fatigue\n",
    "- **Ignoring computational cost:** Disable heavy features (interactions, correlations) when not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12045434",
   "metadata": {},
   "source": [
    "## Final Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17e436a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact verification:\n",
      "✓ artifacts/reports/per_customer_minimal.html (1,083,308 bytes)\n",
      "✓ artifacts/reports/per_customer_focused.html (1,152,066 bytes)\n",
      "✓ artifacts/metrics/per_customer_metrics.json (187 bytes)\n",
      "\n",
      "✓ Lab 10 complete! Export HTML reports and commit the JSON metrics.\n"
     ]
    }
   ],
   "source": [
    "# Verify all artifacts were created\n",
    "import os\n",
    "\n",
    "artifacts_to_check = [\n",
    "    \"artifacts/reports/per_customer_minimal.html\",\n",
    "    \"artifacts/reports/per_customer_focused.html\",\n",
    "    \"artifacts/metrics/per_customer_metrics.json\"\n",
    "]\n",
    "\n",
    "print(\"Artifact verification:\")\n",
    "for artifact in artifacts_to_check:\n",
    "    exists = os.path.exists(artifact)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    size = os.path.getsize(artifact) if exists else 0\n",
    "    print(f\"{status} {artifact} ({size:,} bytes)\" if exists else f\"{status} {artifact} (not found)\")\n",
    "\n",
    "print(\"\\n✓ Lab 10 complete! Export HTML reports and commit the JSON metrics.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
