{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcd2bf35",
   "metadata": {},
   "source": [
    "# Lab 10 — Data Profiling at Scale with ydata‑profiling\n",
    "\n",
    "**Focus Area:** Data profiling — summary stats, cardinality, distributions, outlier flags, and integrating reports into review\n",
    "\n",
    "> This lab shows how to generate actionable **profiling reports** for medium–large datasets using **ydata‑profiling**, interpret the outputs (summary stats, high‑cardinality, distributions, correlations, outliers), and integrate those artifacts into your review/CI workflow alongside Pandera/Pydantic gates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaddef3",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Produce a **ProfileReport** (full and minimal) and export it to HTML for team review.\n",
    "2. Interpret key sections: **overview**, **variables**, **interactions**, **correlations**, **missingness**, **alerts** (outliers, skew, high cardinality).\n",
    "3. Extract **machine‑readable metrics** from the report to track drift over time.\n",
    "4. Profile **at scale** using sampling, column subsets, and configuration tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fc598",
   "metadata": {},
   "source": [
    "## Prerequisites & Setup\n",
    "\n",
    "- Python 3.13 with `pandas`, `numpy`, `ydata-profiling`, `pyarrow`.\n",
    "- JupyterLab or VS Code with Jupyter extension.\n",
    "- Artifacts (preferred): `artifacts/clean/per_customer_enriched.parquet` and `per_segment.parquet`.\n",
    "\n",
    "If you don't have artifacts, synthesize a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34da5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Try to load existing artifact, or synthesize if not available\n",
    "artifact_path = Path(\"../artifacts/clean/per_customer_enriched.parquet\")\n",
    "\n",
    "if artifact_path.exists():\n",
    "    per_cust_enriched = pd.read_parquet(artifact_path)\n",
    "    print(f\"Loaded {len(per_cust_enriched)} rows from {artifact_path}\")\n",
    "else:\n",
    "    print(\"Artifact not found, synthesizing dataset...\")\n",
    "    rng = np.random.default_rng(0)\n",
    "    N = 50_000\n",
    "    per_cust_enriched = pd.DataFrame({\n",
    "        'CustomerID': [f'C{i:05d}' for i in range(N)],\n",
    "        'country_norm': rng.choice(['USA','DE','SG','BR'], size=N, p=[.58,.18,.16,.08]),\n",
    "        'n_orders': rng.poisson(3, size=N),\n",
    "        'freight_sum': np.round(np.clip(rng.lognormal(3.0, 0.8, size=N), 0, 2e5), 2),\n",
    "        'freight_mean': np.round(np.clip(rng.lognormal(2.5, 0.6, size=N), 0, 1e4), 2),\n",
    "        'is_adult': rng.random(size=N) > 0.1,\n",
    "        'is_high_value': rng.random(size=N) > 0.9,\n",
    "    })\n",
    "\n",
    "per_cust_enriched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774d694",
   "metadata": {},
   "source": [
    "## Part A — Generate a Minimal Profile\n",
    "\n",
    "### A1. Basic report (minimal config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285af80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "# Create reports directory if it doesn't exist\n",
    "Path(\"../artifacts/reports\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sample data if too large\n",
    "sample = per_cust_enriched.sample(15_000, random_state=42) if len(per_cust_enriched) > 15_000 else per_cust_enriched\n",
    "\n",
    "profile_min = ProfileReport(\n",
    "    sample,\n",
    "    title=\"Per-Customer Enriched — Minimal Profile\",\n",
    "    minimal=True,  # disables heavy calculations (e.g., interactions)\n",
    "    explorative=True,\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "profile_min.to_file(\"../artifacts/reports/per_customer_minimal.html\")\n",
    "print(\"Minimal profile saved to: ../artifacts/reports/per_customer_minimal.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601109a",
   "metadata": {},
   "source": [
    "### A2. Read the overview\n",
    "\n",
    "- **Warnings/Alerts:** high cardinality (e.g., `CustomerID`), skewed distributions (`freight_sum`), zeros inflation.\n",
    "- **Missingness:** ensure expected null rates (should be near 0 post‑cleaning).\n",
    "\n",
    "**Checkpoint:** List 3 alerts the report shows and classify them: quality issue vs expected property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b85d0f",
   "metadata": {},
   "source": [
    "**Analysis of Alerts:**\n",
    "\n",
    "1. **High cardinality in CustomerID** - Expected property (unique identifier)\n",
    "2. **Skewed distribution in freight_sum** - Expected property (log-normal distribution is typical for monetary values)\n",
    "3. **Check for any zero inflation or missing values** - Would be a quality issue if unexpected\n",
    "\n",
    "*(Review the HTML report to identify specific alerts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752c0ae",
   "metadata": {},
   "source": [
    "## Part B — Focused Full Profile (column subset + tuned)\n",
    "\n",
    "### B1. Choose columns and tune config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac774762",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"country_norm\",\"n_orders\",\"freight_sum\",\"freight_mean\",\"is_high_value\"]\n",
    "subset = per_cust_enriched[cols].copy()\n",
    "\n",
    "profile_cfg = {\n",
    "    \"title\": \"Per-Customer Enriched — Focused Profile\",\n",
    "    \"dataset\": {\"description\": \"Subset profile for review & CI\"},\n",
    "    \"variables\": {\"descriptions\": {\n",
    "        \"freight_sum\": \"Total freight per customer (currency units)\",\n",
    "        \"freight_mean\": \"Average freight per order\",\n",
    "        \"n_orders\": \"Order count per customer\"\n",
    "    }},\n",
    "    \"correlations\": {\"pearson\": {\"calculate\": True}, \"spearman\": {\"calculate\": True}},\n",
    "    \"missing_diagrams\": {\"heatmap\": True, \"dendrogram\": False},\n",
    "}\n",
    "\n",
    "profile_full = ProfileReport(\n",
    "    subset,\n",
    "    title=profile_cfg[\"title\"],\n",
    "    explorative=True,\n",
    "    minimal=False,\n",
    "    correlations=profile_cfg[\"correlations\"],\n",
    "    progress_bar=True\n",
    ")\n",
    "\n",
    "profile_full.to_file(\"../artifacts/reports/per_customer_focused.html\")\n",
    "print(\"Focused profile saved to: ../artifacts/reports/per_customer_focused.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaf31c",
   "metadata": {},
   "source": [
    "### B2. Interpret variables & correlations\n",
    "\n",
    "- **Variables tab:** check **distributions**, **zeros**, **distinct counts** (cardinality), **outlier flags** for `freight_sum`.\n",
    "- **Correlations:** look for strong positive or negative relationships (e.g., `n_orders` vs `freight_sum`), and verify they are **business‑plausible**.\n",
    "\n",
    "**Checkpoint:** Name one correlation you'd expect and whether the profile confirms it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687929f",
   "metadata": {},
   "source": [
    "**Expected Correlation:**\n",
    "\n",
    "We would expect a **positive correlation between `n_orders` and `freight_sum`** - customers who place more orders should have higher total freight costs. The profile report should confirm this relationship with a positive Pearson/Spearman coefficient.\n",
    "\n",
    "*(Review the Correlations section in the HTML report to verify)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e44ec",
   "metadata": {},
   "source": [
    "## Part C — Extract Metrics Programmatically\n",
    "\n",
    "### C1. Get summary dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = profile_full.to_dict()\n",
    "\n",
    "# Example: pull high-level stats\n",
    "n_rows = summary['table']['n']\n",
    "var_summaries = {k: v for k, v in summary['variables'].items() if k in cols}\n",
    "\n",
    "print(f\"Number of rows: {n_rows}\")\n",
    "print(f\"Variables analyzed: {list(var_summaries.keys())[:3]}\")\n",
    "n_rows, list(var_summaries)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d694d18c",
   "metadata": {},
   "source": [
    "### C2. Build a compact drift tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "metrics = {\n",
    "    \"n_rows\": n_rows,\n",
    "    \"freight_sum_mean\": var_summaries['freight_sum']['mean'],\n",
    "    \"freight_sum_std\": var_summaries['freight_sum']['std'],\n",
    "    \"n_orders_mean\": var_summaries['n_orders']['mean'],\n",
    "    \"n_orders_distinct\": var_summaries['n_orders']['distinct_count'],\n",
    "    \"country_cardinality\": var_summaries['country_norm']['distinct_count'],\n",
    "}\n",
    "\n",
    "Path(\"../artifacts/metrics\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"../artifacts/metrics/per_customer_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Metrics saved to: ../artifacts/metrics/per_customer_metrics.json\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc01837",
   "metadata": {},
   "source": [
    "### C3. Compare to a baseline (simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake baseline and compare for illustration\n",
    "baseline = {k: (v * 0.9 if isinstance(v, (int, float)) else v) for k, v in metrics.items()}\n",
    "\n",
    "def pct_diff(a, b):\n",
    "    return None if b == 0 else (a - b) / b\n",
    "\n",
    "delta = {k: pct_diff(metrics[k], baseline[k]) if isinstance(metrics[k], (int, float)) else None for k in metrics}\n",
    "delta_formatted = {k: round(v, 3) for k, v in delta.items() if v is not None}\n",
    "\n",
    "print(\"Percentage differences from baseline:\")\n",
    "delta_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f45f6c",
   "metadata": {},
   "source": [
    "**Checkpoint:** Which metric movements would trigger investigation (>20% by default)?\n",
    "\n",
    "In this simulated example, all metrics show ~11% change (1/0.9 - 1 ≈ 0.111). In a real scenario:\n",
    "- Changes > 20% in `freight_sum_mean` or `freight_sum_std` would indicate significant data drift\n",
    "- Changes in `country_cardinality` might indicate new markets or data quality issues\n",
    "- Large changes in `n_orders_mean` could signal business shifts or data collection problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3fb97d",
   "metadata": {},
   "source": [
    "## Part D — Operate at Scale & Integrate in Review\n",
    "\n",
    "### D1. Tips for biggish data\n",
    "\n",
    "- **Sampling:** `.sample(50_000)` for profiles; keep full data for Pandera validation.\n",
    "- **Disable heavy bits:** `minimal=True` or turn off interactions/correlations you don't need.\n",
    "- **Column subsets:** profile only **review‑critical** columns per PR.\n",
    "- **Persist artifacts:** write to `artifacts/reports/` and link in your PR checklist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8a43a",
   "metadata": {},
   "source": [
    "### D2. Review checklist snippet (add to PR template)\n",
    "\n",
    "- [ ] Profile HTML attached (`per_customer_focused.html`).\n",
    "- [ ] Key metrics JSON updated (`per_customer_metrics.json`).\n",
    "- [ ] Any new high‑cardinality or outlier alerts acknowledged.\n",
    "- [ ] Pandera schema still passes (link to Lab 3B test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f5107",
   "metadata": {},
   "source": [
    "### D3. Wire to CI (concept)\n",
    "\n",
    "- Save `profile.to_file()` output as a CI artifact.\n",
    "- Parse `profile.to_dict()` and **fail** if critical thresholds are exceeded (e.g., null rate, cardinality spike, extreme mean/STD drift).\n",
    "\n",
    "Example CI check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78568c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example CI validation function\n",
    "def validate_metrics_for_ci(metrics, baseline, thresholds):\n",
    "    \"\"\"\n",
    "    Validate metrics against baseline with configurable thresholds.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Current metrics dict\n",
    "        baseline: Baseline metrics dict\n",
    "        thresholds: Dict of metric_name -> max_allowed_pct_change\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (passed: bool, failures: list)\n",
    "    \"\"\"\n",
    "    failures = []\n",
    "    \n",
    "    for metric, threshold in thresholds.items():\n",
    "        if metric not in metrics or metric not in baseline:\n",
    "            continue\n",
    "            \n",
    "        current = metrics[metric]\n",
    "        base = baseline[metric]\n",
    "        \n",
    "        if base == 0:\n",
    "            continue\n",
    "            \n",
    "        pct_change = abs((current - base) / base)\n",
    "        \n",
    "        if pct_change > threshold:\n",
    "            failures.append({\n",
    "                'metric': metric,\n",
    "                'current': current,\n",
    "                'baseline': base,\n",
    "                'pct_change': round(pct_change * 100, 2),\n",
    "                'threshold': round(threshold * 100, 2)\n",
    "            })\n",
    "    \n",
    "    return len(failures) == 0, failures\n",
    "\n",
    "# Example usage\n",
    "thresholds = {\n",
    "    'freight_sum_mean': 0.20,  # 20% max change\n",
    "    'freight_sum_std': 0.25,   # 25% max change\n",
    "    'n_orders_mean': 0.15,     # 15% max change\n",
    "    'country_cardinality': 0.10  # 10% max change (new countries should be rare)\n",
    "}\n",
    "\n",
    "passed, failures = validate_metrics_for_ci(metrics, baseline, thresholds)\n",
    "\n",
    "if passed:\n",
    "    print(\"✓ All metrics within acceptable thresholds\")\n",
    "else:\n",
    "    print(\"✗ Metrics validation failed:\")\n",
    "    for failure in failures:\n",
    "        print(f\"  {failure['metric']}: {failure['pct_change']}% change (threshold: {failure['threshold']}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc845a65",
   "metadata": {},
   "source": [
    "## Solution Snippets (reference)\n",
    "\n",
    "### Minimal profile one‑liner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9179d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick minimal profile for rapid iteration\n",
    "# ProfileReport(df.sample(20_000), minimal=True, explorative=True).to_file(\"../artifacts/reports/df_min.html\")\n",
    "print(\"Example code - uncomment to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a09430b",
   "metadata": {},
   "source": [
    "### Turn off heavy interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53fa317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile with correlations but without interactions\n",
    "# ProfileReport(df, minimal=False, correlations={\"pearson\": {\"calculate\": True}}, interactions=None)\n",
    "print(\"Example code - uncomment to run\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb19ee",
   "metadata": {},
   "source": [
    "### Extract a null‑rate table from dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23809fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract null rates from profile summary\n",
    "summary = profile_full.to_dict()\n",
    "null_rates = {k: v.get('p_missing', None) for k, v in summary['variables'].items()}\n",
    "null_rates_formatted = {k: round(v, 4) for k, v in null_rates.items() if v is not None}\n",
    "\n",
    "print(\"Null rates by column:\")\n",
    "null_rates_formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2523fe8",
   "metadata": {},
   "source": [
    "## Wrap‑Up\n",
    "\n",
    "Answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1ceda",
   "metadata": {},
   "source": [
    "### 1. List two alerts flagged by the profile and how you'd mitigate them.\n",
    "\n",
    "**Alert 1: High cardinality in CustomerID**\n",
    "- **Mitigation:** This is expected for a unique identifier. Document as expected behavior and exclude from cardinality warnings in CI. Consider hashing or pseudonymizing if privacy is a concern.\n",
    "\n",
    "**Alert 2: Skewed distribution in freight_sum**\n",
    "- **Mitigation:** Log-normal distributions are common for monetary values. Document this as expected business behavior. Consider using log-scale transformations for ML models. Monitor outliers separately to catch data quality issues.\n",
    "\n",
    "*(Additional alerts to check in the actual report: zeros inflation, extreme values, unexpected missing data)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c46fa",
   "metadata": {},
   "source": [
    "### 2. Paste two metrics from your JSON that you will watch in CI and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13580bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key metrics to monitor\n",
    "ci_metrics = {\n",
    "    \"freight_sum_mean\": metrics[\"freight_sum_mean\"],\n",
    "    \"country_cardinality\": metrics[\"country_cardinality\"]\n",
    "}\n",
    "\n",
    "print(\"Key metrics for CI monitoring:\")\n",
    "print(json.dumps(ci_metrics, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08ce8e8",
   "metadata": {},
   "source": [
    "**Metrics to watch in CI:**\n",
    "\n",
    "1. **`freight_sum_mean`**: Monitors the average total freight per customer. Large changes could indicate:\n",
    "   - Pricing changes in the business\n",
    "   - Data quality issues (wrong currency, missing decimals)\n",
    "   - Shift in customer segments\n",
    "   - Threshold: Alert if >20% change from baseline\n",
    "\n",
    "2. **`country_cardinality`**: Tracks the number of distinct countries. Changes could indicate:\n",
    "   - Expansion into new markets (expected if planned)\n",
    "   - Data quality issues (invalid country codes)\n",
    "   - Changes in data collection or normalization logic\n",
    "   - Threshold: Alert if >10% change (should be relatively stable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a51fb1",
   "metadata": {},
   "source": [
    "### 3. Where in the pipeline will you generate and store the profiling report?\n",
    "\n",
    "**Pipeline Integration Strategy:**\n",
    "\n",
    "1. **Generation Points:**\n",
    "   - **Post-cleaning stage:** After data cleaning/enrichment but before loading to production\n",
    "   - **Pre-deployment validation:** As part of CI/CD before promoting to production\n",
    "   - **Scheduled monitoring:** Weekly/monthly for production data drift detection\n",
    "\n",
    "2. **Storage Locations:**\n",
    "   - **HTML Reports:** `artifacts/reports/` directory (versioned or timestamped)\n",
    "   - **Metrics JSON:** `artifacts/metrics/` for programmatic access and CI checks\n",
    "   - **CI Artifacts:** Uploaded as build artifacts in CI/CD system (GitHub Actions, GitLab CI, etc.)\n",
    "   - **Object Storage:** S3/Azure Blob for long-term archival and historical comparison\n",
    "\n",
    "3. **Integration Points:**\n",
    "   - Link HTML reports in PR descriptions for reviewer access\n",
    "   - Automated CI checks parse JSON metrics and fail builds on threshold violations\n",
    "   - Dashboard integration showing metric trends over time\n",
    "   - Alert system for significant drift detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d775eb8c",
   "metadata": {},
   "source": [
    "## Common Pitfalls\n",
    "\n",
    "- **Running full profiles on multi‑million rows:** Always sample large datasets to reasonable size (10-50k rows)\n",
    "- **Forgetting to sample:** Can cause memory issues and extremely long run times\n",
    "- **Not persisting artifacts:** Reports and metrics should be version-controlled or archived\n",
    "- **Treating expected skew as an error:** Document and accept expected business patterns (log-normal distributions, seasonal effects)\n",
    "- **Over-alerting in CI:** Set appropriate thresholds to avoid alert fatigue\n",
    "- **Ignoring computational cost:** Disable heavy features (interactions, correlations) when not needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12045434",
   "metadata": {},
   "source": [
    "## Final Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e436a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all artifacts were created\n",
    "import os\n",
    "\n",
    "artifacts_to_check = [\n",
    "    \"../artifacts/reports/per_customer_minimal.html\",\n",
    "    \"../artifacts/reports/per_customer_focused.html\",\n",
    "    \"../artifacts/metrics/per_customer_metrics.json\"\n",
    "]\n",
    "\n",
    "print(\"Artifact verification:\")\n",
    "for artifact in artifacts_to_check:\n",
    "    exists = os.path.exists(artifact)\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    size = os.path.getsize(artifact) if exists else 0\n",
    "    print(f\"{status} {artifact} ({size:,} bytes)\" if exists else f\"{status} {artifact} (not found)\")\n",
    "\n",
    "print(\"\\n✓ Lab 10 complete! Export HTML reports and commit the JSON metrics.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
